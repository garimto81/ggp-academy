# í”„ë¡œë•ì…˜ ê¸°ìˆ  ì‹œìŠ¤í…œ ê°ì£¼ ë¬¸ì„œ
**FOOTNOTES_TECHNICAL_SYSTEMS.md**

> **ë¬¸ì„œ ëª©ì **: MASTER_PLAN Chapter 2 "í”„ë¡œë•ì…˜ ê¸°ìˆ  ì‹œìŠ¤í…œ"ì— ë“±ì¥í•˜ëŠ” í•µì‹¬ ê¸°ìˆ  ìš©ì–´ ë° ê°œë…ì— ëŒ€í•œ ìƒì„¸í•œ ê°ì£¼ ë¬¸ì„œ
>
> **ëŒ€ìƒ ë…ì**: GG Production í¬ì»¤ í”„ë¡œë•ì…˜ ì „ë¬¸ê°€ ì–‘ì„± ê³¼ì • ì°¸ì—¬ì
>
> **ì‘ì„± ì›ì¹™**:
> - ê° ìš©ì–´ì— ëŒ€í•´ ì •ì˜, ê¸°ìˆ  ì‚¬ì–‘, ì‹¤ë¬´ ì ìš©, ì˜ˆì‹œ ì½”ë“œ, íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì œê³µ
> - ë°©ì†¡ í”„ë¡œë•ì…˜ ê´€ì ì—ì„œì˜ ì‹¤ìš©ì  ì ‘ê·¼
> - ì´ˆë³´ìë„ ì´í•´ ê°€ëŠ¥í•œ ë‹¨ê³„ì  ì„¤ëª…
> - ì‹¤ì œ í¬ì»¤ í† ë„ˆë¨¼íŠ¸ ë°©ì†¡ ì‚¬ë¡€ ì¤‘ì‹¬

---

## ğŸ“‘ ëª©ì°¨

### Section 1: ì¹´ë©”ë¼ ì‹œìŠ¤í…œ
1. [FR7 ë¡œë´‡ ì¹´ë©”ë¼](#1-fr7-robot-camera)
2. [Exposure Triangle (ë…¸ì¶œ ì‚¼ê°í˜•)](#2-exposure-triangle)
3. [White Balance (í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤)](#3-white-balance)
4. [Focus Pulling (í¬ì»¤ìŠ¤ í’€ë§)](#4-focus-pulling)
5. [PTZ (Pan-Tilt-Zoom)](#5-ptz-camera)

### Section 2: ì˜ìƒ ì‹ í˜¸ ë° í‘œì¤€
6. [SDI (Serial Digital Interface)](#6-sdi-signal)
7. [HDMI vs SDI](#7-hdmi-vs-sdi)
8. [4K/UHD Resolution](#8-4k-uhd-resolution)
9. [Frame Rate (í”„ë ˆì„ ë ˆì´íŠ¸)](#9-frame-rate)
10. [SMPTE Timecode](#10-smpte-timecode)

### Section 3: ì˜¤ë””ì˜¤ ì—”ì§€ë‹ˆì–´ë§
11. [Gain Staging (ê²Œì¸ ìŠ¤í…Œì´ì§•)](#11-gain-staging)
12. [Compression (ì˜¤ë””ì˜¤ ì••ì¶•)](#12-audio-compression)
13. [EQ (Equalization)](#13-equalization)
14. [Mixing Console (ë¯¹ì‹± ì½˜ì†”)](#14-mixing-console)
15. [Phantom Power (íŒ¬í…€ íŒŒì›Œ)](#15-phantom-power)

### Section 4: ë„¤íŠ¸ì›Œí¬ ì¸í”„ë¼
16. [VLAN (Virtual LAN)](#16-vlan)
17. [QoS (Quality of Service)](#17-qos)
18. [Bandwidth Calculation](#18-bandwidth-calculation)
19. [Latency vs Jitter](#19-latency-vs-jitter)
20. [IP Video (SMPTE ST 2110)](#20-ip-video)

### Section 5: ìŠ¤ìœ„ì¹­ ë° ì œì–´
21. [Vision Mixer (ë¹„ë””ì˜¤ ìŠ¤ìœ„ì²˜)](#21-vision-mixer)
22. [Program vs Preview](#22-program-vs-preview)
23. [DSK (Downstream Keyer)](#23-dsk)
24. [Tally System](#24-tally-system)
25. [Macro Programming](#25-macro-programming)

### Section 6: ì»¬ëŸ¬ ê´€ë¦¬
26. [LUT (Look-Up Table)](#26-lut)
27. [Color Space (Rec.709 vs Rec.2020)](#27-color-space)
28. [Log Gamma Curves](#28-log-gamma)
29. [Vectorscope & Waveform](#29-vectorscope-waveform)
30. [Color Calibration](#30-color-calibration)

---

## Section 1: ì¹´ë©”ë¼ ì‹œìŠ¤í…œ

<a name="1-fr7-robot-camera"></a>
## 1ï¸âƒ£ FR7 ë¡œë´‡ ì¹´ë©”ë¼ (FR7 Robot Camera)

### ğŸ“˜ ì •ì˜
**FR7 ë¡œë´‡ ì¹´ë©”ë¼**ëŠ” Sonyê°€ ê°œë°œí•œ ë¦¬ëª¨íŠ¸ ì œì–´ ë¡œë´‡ ì¹´ë©”ë¼ ì‹œìŠ¤í…œìœ¼ë¡œ, 360ë„ ë¬´í•œ íšŒì „(Pan), Â±210ë„ í‹¸íŠ¸(Tilt), ê´‘í•™ ì¤Œ ê¸°ëŠ¥ì„ ì›ê²©ìœ¼ë¡œ ì œì–´í•  ìˆ˜ ìˆëŠ” í”„ë¡œí˜ì…”ë„ ë°©ì†¡ìš© ì¹´ë©”ë¼ì…ë‹ˆë‹¤.

### ğŸ”§ ê¸°ìˆ  ì‚¬ì–‘

#### í•˜ë“œì›¨ì–´ êµ¬ì„±
```yaml
ì¹´ë©”ë¼ í—¤ë“œ:
  ëª¨ë¸: Sony Î±7R IV / Î±7S III
  ì„¼ì„œ: 35mm í’€í”„ë ˆì„ CMOS
  í•´ìƒë„: 4K 60fps / FHD 120fps
  ë§ˆìš´íŠ¸: E-mount (êµì²´ ê°€ëŠ¥)
  ë¬´ê²Œ: ì•½ 2.5kg

ë¡œë´‡ ì•”:
  íšŒì „(Pan): 360ë„ ë¬´í•œ íšŒì „
  í‹¸íŠ¸(Tilt): Â±210ë„
  ì†ë„: 0.01Â°/s ~ 300Â°/s (ê°€ë³€)
  ìœ„ì¹˜ ì •í™•ë„: Â±0.02ë„
  í”„ë¦¬ì…‹: ìµœëŒ€ 99ê°œ ì €ì¥

ì œì–´ ìœ ë‹›:
  ëª¨ë¸: RM-IP500 / RM-IP10
  ì—°ê²°: IP (PoE ì§€ì›) / RS-422
  ë™ì‹œ ì œì–´: ìµœëŒ€ 100ëŒ€
  ì‘ë‹µ ì‹œê°„: <50ms
```

#### ë„¤íŠ¸ì›Œí¬ êµ¬ì„±
```python
# FR7 ì¹´ë©”ë¼ ë„¤íŠ¸ì›Œí¬ ì„¤ì • ì˜ˆì‹œ
class FR7NetworkConfig:
    def __init__(self):
        self.camera_configs = {
            "camera_1": {
                "ip": "192.168.10.101",
                "subnet": "255.255.255.0",
                "gateway": "192.168.10.1",
                "port": 52381,
                "vlan": 10,  # Camera VLAN
                "qos": "EF",  # Expedited Forwarding
                "latency_target": "30ms"
            },
            "camera_2": {
                "ip": "192.168.10.102",
                "subnet": "255.255.255.0",
                "gateway": "192.168.10.1",
                "port": 52381,
                "vlan": 10,
                "qos": "EF",
                "latency_target": "30ms"
            }
        }

    def generate_preset_file(self, camera_id, preset_data):
        """í”„ë¦¬ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±"""
        preset = {
            "preset_id": preset_data["id"],
            "name": preset_data["name"],
            "pan": preset_data["pan"],  # -180.0 ~ +180.0
            "tilt": preset_data["tilt"],  # -105.0 ~ +105.0
            "zoom": preset_data["zoom"],  # 0.0 ~ 1.0 (normalized)
            "focus": preset_data["focus"],  # Auto / Manual
            "iris": preset_data["iris"],  # f/1.4 ~ f/22
            "transition_time": preset_data["speed"]  # seconds
        }
        return preset
```

### ğŸ¯ í¬ì»¤ í…Œì´ë¸” ë°°ì¹˜ ì „ëµ

#### 5ëŒ€ ì¹´ë©”ë¼ êµ¬ì„± (Feature Table)
```
                    [Camera 1]
                   (ì˜¤ë²„í—¤ë“œ)
                        â†“

[Camera 4]  â†  ğŸƒ í…Œì´ë¸” ğŸƒ  â†’  [Camera 5]
(í”Œë ˆì´ì–´ ì¢Œ)                    (í”Œë ˆì´ì–´ ìš°)

         [Camera 2]      [Camera 3]
        (ë”œëŸ¬ ì •ë©´)      (ì¹©/ì¹´ë“œ í´ë¡œì¦ˆì—…)
```

#### ì¹´ë©”ë¼ë³„ í”„ë¦¬ì…‹ ì„¤ì •
```yaml
Camera 1 (ì˜¤ë²„í—¤ë“œ):
  Preset 1 - ì „ì²´ í…Œì´ë¸”:
    pan: 0.0
    tilt: -90.0
    zoom: 0.3
    ìš©ë„: ê²Œì„ ì‹œì‘, ì „ì²´ í˜„í™©

  Preset 2 - ì»¤ë®¤ë‹ˆí‹° ì¹´ë“œ í¬ì»¤ìŠ¤:
    pan: 0.0
    tilt: -80.0
    zoom: 0.7
    ìš©ë„: í”Œë/í„´/ë¦¬ë²„ ê³µê°œ

Camera 2 (ë”œëŸ¬ ì •ë©´):
  Preset 1 - ë”œëŸ¬ ë¯¸ë””ì—„ ìƒ·:
    pan: 0.0
    tilt: 0.0
    zoom: 0.4
    ìš©ë„: ì¹´ë“œ ë°°ë¶„ ì¥ë©´

  Preset 2 - í•¸ë“œ ì•¡ì…˜:
    pan: 0.0
    tilt: -10.0
    zoom: 0.8
    ìš©ë„: ë² íŒ… ì•¡ì…˜ í´ë¡œì¦ˆì—…

Camera 3 (í´ë¡œì¦ˆì—…):
  Preset 1 - ì¹© ìŠ¤íƒ:
    pan: +15.0
    tilt: -30.0
    zoom: 0.9
    ìš©ë„: ì˜¬ì¸ ì¥ë©´

  Preset 2 - ì»¤ë®¤ë‹ˆí‹° ì¹´ë“œ ë””í…Œì¼:
    pan: 0.0
    tilt: -45.0
    zoom: 1.0
    ìš©ë„: ì¹´ë“œ ê³µê°œ ìˆœê°„

Camera 4/5 (í”Œë ˆì´ì–´):
  Preset 1~8 - ê° í”Œë ˆì´ì–´ í¬ì§€ì…˜:
    pan: -120.0 ~ +120.0 (8ëª… ê¸°ì¤€)
    tilt: +5.0
    zoom: 0.6
    ìš©ë„: í”Œë ˆì´ì–´ ë¦¬ì•¡ì…˜
```

### ğŸ’¡ í”„ë¦¬ì…‹ ìë™í™” ì‹œí€€ìŠ¤

#### ì˜¬ì¸ ìƒí™© ìë™ ì‹œí€€ìŠ¤
```python
class AllInSequence:
    def __init__(self, cameras):
        self.cameras = cameras
        self.duration = 0

    def execute(self, player_position, pot_size):
        """ì˜¬ì¸ ìƒí™© ìë™ ì¹´ë©”ë¼ ì‹œí€€ìŠ¤"""
        sequence = [
            # Phase 1: ì˜¬ì¸ ì„ ì–¸ (3ì´ˆ)
            {
                "camera": self.cameras[4],  # í”Œë ˆì´ì–´ ì¹´ë©”ë¼
                "preset": f"player_{player_position}",
                "duration": 3.0,
                "transition": "cut"
            },
            # Phase 2: ì¹© ìŠ¤íƒ í´ë¡œì¦ˆì—… (2ì´ˆ)
            {
                "camera": self.cameras[3],
                "preset": "chip_detail",
                "duration": 2.0,
                "transition": "dissolve"
            },
            # Phase 3: ìƒëŒ€ í”Œë ˆì´ì–´ ë¦¬ì•¡ì…˜ (3ì´ˆ)
            {
                "camera": self.cameras[5],
                "preset": f"player_{self._get_opponent(player_position)}",
                "duration": 3.0,
                "transition": "cut"
            },
            # Phase 4: ì „ì²´ í…Œì´ë¸” (2ì´ˆ)
            {
                "camera": self.cameras[1],
                "preset": "table_wide",
                "duration": 2.0,
                "transition": "dissolve"
            }
        ]

        return sequence

    def _get_opponent(self, position):
        """ì˜¬ì¸ ëŒ€ê²° ìƒëŒ€ ì°¾ê¸°"""
        # ì‹¤ì œë¡œëŠ” ê²Œì„ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´
        return (position + 4) % 8
```

#### ìë™ ì‹œí€€ìŠ¤ ì‹¤í–‰ ì½”ë“œ
```python
import asyncio
from typing import List, Dict

class FR7Automation:
    def __init__(self, controller_ip: str):
        self.controller_ip = controller_ip
        self.active_sequence = None

    async def run_sequence(self, sequence: List[Dict]):
        """ë¹„ë™ê¸° ì‹œí€€ìŠ¤ ì‹¤í–‰"""
        for step in sequence:
            camera = step["camera"]
            preset = step["preset"]
            duration = step["duration"]
            transition = step["transition"]

            # ì¹´ë©”ë¼ í”„ë¦¬ì…‹ í˜¸ì¶œ
            await self.recall_preset(camera, preset, transition)

            # ì§€ì •ëœ ì‹œê°„ë§Œí¼ ìœ ì§€
            await asyncio.sleep(duration)

    async def recall_preset(self, camera_id: str, preset_name: str, transition: str):
        """í”„ë¦¬ì…‹ í˜¸ì¶œ ëª…ë ¹ ì „ì†¡"""
        command = {
            "camera": camera_id,
            "command": "RecallPreset",
            "preset": preset_name,
            "transition": transition,
            "speed": self._get_transition_speed(transition)
        }

        # TCP/IP ë˜ëŠ” REST APIë¡œ ëª…ë ¹ ì „ì†¡
        await self._send_command(command)

    def _get_transition_speed(self, transition_type: str) -> float:
        """ì „í™˜ íƒ€ì…ë³„ ì†ë„ ì„¤ì •"""
        speeds = {
            "cut": 0.0,  # ì¦‰ì‹œ ì „í™˜
            "dissolve": 1.5,  # 1.5ì´ˆ ë””ì¡¸ë¸Œ
            "slow_pan": 3.0  # 3ì´ˆ ëŠë¦° íŒ¬
        }
        return speeds.get(transition_type, 1.0)

    async def _send_command(self, command: Dict):
        """ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ëª…ë ¹ ì „ì†¡"""
        # REST API ì˜ˆì‹œ
        import aiohttp

        url = f"http://{self.controller_ip}/api/v1/camera/control"

        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=command) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    raise Exception(f"Camera command failed: {response.status}")
```

### ğŸ¬ ì‹¤ì „ ìš´ì˜ ì›Œí¬í”Œë¡œìš°

#### í† ë„ˆë¨¼íŠ¸ ì‹œì‘ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
```markdown
# FR7 ì¹´ë©”ë¼ ì„¸íŒ… ì²´í¬ë¦¬ìŠ¤íŠ¸

## 1ì‹œê°„ ì „ (T-60)
- [ ] ëª¨ë“  FR7 ì¹´ë©”ë¼ ì „ì› ON
- [ ] ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸ (ping í…ŒìŠ¤íŠ¸)
- [ ] RM-IP500 ì»¨íŠ¸ë¡¤ëŸ¬ ì—°ê²° í™•ì¸
- [ ] ì¹´ë©”ë¼ í—¤ë“œ ë Œì¦ˆ ì²­ì†Œ
- [ ] ì´ˆì  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (í…ŒìŠ¤íŠ¸ ì°¨íŠ¸)

## 30ë¶„ ì „ (T-30)
- [ ] í”„ë¦¬ì…‹ 1~99 ë™ì‘ í…ŒìŠ¤íŠ¸
- [ ] ìë™ ì‹œí€€ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] ì¡°ëª… ë³€í™”ì— ë”°ë¥¸ ë…¸ì¶œ ì¡°ì •
- [ ] ë°±ì—… ì¹´ë©”ë¼ (PTZ) ì¤€ë¹„
- [ ] Tally ì‹œìŠ¤í…œ ì—°ë™ í™•ì¸

## 10ë¶„ ì „ (T-10)
- [ ] ìµœì¢… í”„ë¦¬ì…‹ ìœ„ì¹˜ í™•ì¸
- [ ] ì „í™˜ ì†ë„ ìµœì í™”
- [ ] ìˆ˜ë™ ì œì–´ ë°±ì—… ì¤€ë¹„
- [ ] ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì²´í¬ (í† í‚¤)
```

#### ë¼ì´ë¸Œ ì¤‘ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
```python
class FR7Troubleshooting:
    """FR7 ì‹¤ì‹œê°„ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.error_log = []
        self.backup_cameras = []

    def check_camera_status(self, camera_id: str) -> Dict:
        """ì¹´ë©”ë¼ ìƒíƒœ ì²´í¬"""
        status = {
            "network": self._check_network(camera_id),
            "power": self._check_power(camera_id),
            "position": self._check_position_accuracy(camera_id),
            "video_output": self._check_video_signal(camera_id)
        }

        if not all(status.values()):
            self._trigger_failover(camera_id, status)

        return status

    def _trigger_failover(self, camera_id: str, error_status: Dict):
        """ì¥ì•  ë°œìƒ ì‹œ ë°±ì—… ì¹´ë©”ë¼ë¡œ ì „í™˜"""
        error_type = self._identify_error(error_status)

        if error_type == "network_timeout":
            # ë„¤íŠ¸ì›Œí¬ ë³µêµ¬ ì‹œë„ (3ì´ˆ íƒ€ì„ì•„ì›ƒ)
            self._attempt_reconnect(camera_id, timeout=3.0)

        elif error_type == "position_drift":
            # ìœ„ì¹˜ ì¬ìº˜ë¦¬ë¸Œë ˆì´ì…˜
            self._recalibrate_position(camera_id)

        elif error_type == "critical_failure":
            # ë°±ì—… ì¹´ë©”ë¼ë¡œ ì¦‰ì‹œ ì „í™˜
            backup = self._get_backup_camera(camera_id)
            self._switch_to_backup(camera_id, backup)

            # ì•Œë¦¼ ì „ì†¡
            self._notify_td(f"Camera {camera_id} failed, switched to {backup}")

    def _identify_error(self, status: Dict) -> str:
        """ì—ëŸ¬ íƒ€ì… ë¶„ë¥˜"""
        if not status["network"]:
            return "network_timeout"
        elif not status["position"]:
            return "position_drift"
        elif not status["video_output"]:
            return "critical_failure"
        return "unknown"
```

### ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

#### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
```python
import time
from dataclasses import dataclass

@dataclass
class CameraMetrics:
    """ì¹´ë©”ë¼ ì„±ëŠ¥ ì§€í‘œ"""
    camera_id: str
    response_time_ms: float
    position_accuracy: float  # degrees
    preset_recalls: int
    errors: int
    uptime_seconds: float

class FR7Monitor:
    def __init__(self):
        self.metrics = {}
        self.alert_thresholds = {
            "response_time": 100,  # ms
            "position_accuracy": 0.05,  # degrees
            "error_rate": 0.01  # 1%
        }

    def collect_metrics(self, camera_id: str):
        """ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘"""
        start = time.time()

        # ì‘ë‹µ ì‹œê°„ ì¸¡ì •
        response = self._send_test_command(camera_id)
        response_time = (time.time() - start) * 1000  # ms

        # ìœ„ì¹˜ ì •í™•ë„ ì¸¡ì •
        accuracy = self._measure_position_accuracy(camera_id)

        # ë©”íŠ¸ë¦­ ì €ì¥
        if camera_id not in self.metrics:
            self.metrics[camera_id] = CameraMetrics(
                camera_id=camera_id,
                response_time_ms=response_time,
                position_accuracy=accuracy,
                preset_recalls=0,
                errors=0,
                uptime_seconds=0.0
            )
        else:
            self.metrics[camera_id].response_time_ms = response_time
            self.metrics[camera_id].position_accuracy = accuracy

        # ì„ê³„ê°’ ì²´í¬
        self._check_alerts(camera_id)

    def _check_alerts(self, camera_id: str):
        """ì•Œë¦¼ ì¡°ê±´ ì²´í¬"""
        metrics = self.metrics[camera_id]

        if metrics.response_time_ms > self.alert_thresholds["response_time"]:
            self._send_alert(f"Camera {camera_id}: High latency ({metrics.response_time_ms}ms)")

        if metrics.position_accuracy > self.alert_thresholds["position_accuracy"]:
            self._send_alert(f"Camera {camera_id}: Position drift ({metrics.position_accuracy}Â°)")

    def generate_report(self) -> str:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = "=== FR7 Camera Performance Report ===\n\n"

        for camera_id, metrics in self.metrics.items():
            report += f"Camera: {camera_id}\n"
            report += f"  Response Time: {metrics.response_time_ms:.2f}ms\n"
            report += f"  Position Accuracy: {metrics.position_accuracy:.3f}Â°\n"
            report += f"  Preset Recalls: {metrics.preset_recalls}\n"
            report += f"  Errors: {metrics.errors}\n"
            report += f"  Uptime: {metrics.uptime_seconds/3600:.2f}h\n"
            report += f"  Error Rate: {(metrics.errors/max(metrics.preset_recalls,1))*100:.2f}%\n\n"

        return report
```

### ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

#### ë¬¸ì œ 1: ì¹´ë©”ë¼ ì‘ë‹µ ì—†ìŒ
```markdown
ì¦ìƒ: í”„ë¦¬ì…‹ í˜¸ì¶œ ì‹œ ì¹´ë©”ë¼ê°€ ì›€ì§ì´ì§€ ì•ŠìŒ

ì§„ë‹¨ ë‹¨ê³„:
1. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
   ```bash
   ping 192.168.10.101
   ```

2. ì¹´ë©”ë¼ ì „ì› í™•ì¸
   - Power LED ìƒíƒœ
   - PoE ê³µê¸‰ ì „ì•• (48V)

3. ì»¨íŠ¸ë¡¤ëŸ¬ ë¡œê·¸ í™•ì¸
   ```bash
   tail -f /var/log/rm-ip500/camera_control.log
   ```

í•´ê²° ë°©ë²•:
- ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ: ìŠ¤ìœ„ì¹˜ í¬íŠ¸ ë¦¬ì…‹
- ì „ì› ë¬¸ì œ: PoE ì¸ì í„° êµì²´
- íŒì›¨ì–´ ì˜¤ë¥˜: ì¹´ë©”ë¼ ì¬ë¶€íŒ… (30ì´ˆ ëŒ€ê¸°)
```

#### ë¬¸ì œ 2: ìœ„ì¹˜ ë“œë¦¬í”„íŠ¸ (Position Drift)
```markdown
ì¦ìƒ: í”„ë¦¬ì…‹ ìœ„ì¹˜ê°€ ì ì°¨ í‹€ì–´ì§

ì›ì¸:
- ê¸°ê³„ì  ë°±ë˜ì‹œ (Backlash)
- ì¸ì½”ë” ì˜¤ì°¨ ëˆ„ì 
- ì§„ë™ ì˜í–¥

í•´ê²° ë°©ë²•:
1. í™ˆ í¬ì§€ì…˜ ì¬ì„¤ì •
   - Menu â†’ Maintenance â†’ Initialize Home Position

2. ì „ì²´ í”„ë¦¬ì…‹ ì¬ìº˜ë¦¬ë¸Œë ˆì´ì…˜
   ```python
   def recalibrate_all_presets(camera_id):
       for preset_id in range(1, 100):
           # í”„ë¦¬ì…‹ í˜¸ì¶œ
           recall_preset(camera_id, preset_id)
           time.sleep(2)

           # í˜„ì¬ ìœ„ì¹˜ ì €ì¥ (ë®ì–´ì“°ê¸°)
           save_current_position(camera_id, preset_id)
   ```

3. ì •ê¸° ì ê²€ (ë§¤ì›”)
   - ë¡œë´‡ ì•” ê¸°ê³„ì  ì ê²€
   - ì¸ì½”ë” ì²­ì†Œ
   - íŒì›¨ì–´ ì—…ë°ì´íŠ¸
```

---

<a name="2-exposure-triangle"></a>
## 2ï¸âƒ£ Exposure Triangle (ë…¸ì¶œ ì‚¼ê°í˜•)

### ğŸ“˜ ì •ì˜
**ë…¸ì¶œ ì‚¼ê°í˜•**ì€ ì‚¬ì§„ ë° ì˜ìƒ ì´¬ì˜ì—ì„œ ì ì • ë…¸ì¶œì„ ê²°ì •í•˜ëŠ” ì„¸ ê°€ì§€ í•µì‹¬ ìš”ì†Œì¸ **ISO (ê°ë„)**, **Shutter Speed (ì…”í„° ì†ë„)**, **Aperture (ì¡°ë¦¬ê°œ)**ì˜ ìƒí˜¸ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°œë…ì…ë‹ˆë‹¤.

### ğŸ”§ ì„¸ ê°€ì§€ ìš”ì†Œ

#### 1. ISO (ê°ë„)
```yaml
ì •ì˜: ì´ë¯¸ì§€ ì„¼ì„œì˜ ë¹›ì— ëŒ€í•œ ë¯¼ê°ë„

ë²”ìœ„:
  Native ISO: 100 ~ 6400 (ìµœì  í™”ì§ˆ)
  Extended ISO: 50 / 12800 / 25600 (í™”ì§ˆ ì €í•˜)

íŠ¹ì„±:
  ë‚®ì€ ISO (100-400):
    - ê¹¨ë—í•œ ì´ë¯¸ì§€
    - ë…¸ì´ì¦ˆ ìµœì†Œí™”
    - ë°ì€ ì¡°ëª… í•„ìš”

  ì¤‘ê°„ ISO (800-3200):
    - ì•½ê°„ì˜ ë…¸ì´ì¦ˆ
    - ì¼ë°˜ì ì¸ ì‹¤ë‚´ ì´¬ì˜
    - ê· í˜•ìˆëŠ” ì„ íƒ

  ë†’ì€ ISO (6400+):
    - ì‹¬í•œ ë…¸ì´ì¦ˆ/ê·¸ë ˆì¸
    - ì–´ë‘ìš´ í™˜ê²½
    - ë¹„ìƒ ìƒí™©ë§Œ ì‚¬ìš©
```

#### 2. Shutter Speed (ì…”í„° ì†ë„)
```yaml
ì •ì˜: ì„¼ì„œê°€ ë¹›ì— ë…¸ì¶œë˜ëŠ” ì‹œê°„

í¬ì»¤ ë°©ì†¡ ê¶Œì¥ê°’:
  ì¼ë°˜ ìƒ·: 1/50s (PAL), 1/60s (NTSC)
  180ë„ ì…”í„° ë£° ì ìš©

ë²”ìœ„ì™€ ìš©ë„:
  Fast (1/500s ~ 1/2000s):
    - ë¹ ë¥¸ ë™ì‘ (ì¹´ë“œ ë°°ë¶„)
    - ëª¨ì…˜ ë¸”ëŸ¬ ìµœì†Œí™”
    - ë§ì€ ë¹› í•„ìš”

  Standard (1/50s ~ 1/100s):
    - ìì—°ìŠ¤ëŸ¬ìš´ ëª¨ì…˜
    - ë°©ì†¡ í‘œì¤€
    - 24fps, 25fps, 30fps ë§¤ì¹­

  Slow (1/25s ~ 1/4s):
    - ëª¨ì…˜ ë¸”ëŸ¬ ì¦ê°€
    - ì €ì¡°ë„ í™˜ê²½
    - ì¹´ë©”ë¼ ê³ ì • í•„ìˆ˜
```

#### 3. Aperture (ì¡°ë¦¬ê°œ / F-stop)
```yaml
ì •ì˜: ë Œì¦ˆë¥¼ í†µê³¼í•˜ëŠ” ë¹›ì˜ ì–‘ ì¡°ì ˆ

í‘œê¸°ë²•: f/1.4, f/2.8, f/5.6, f/11, f/22
  (ìˆ«ìê°€ ì‘ì„ìˆ˜ë¡ ì¡°ë¦¬ê°œê°€ ë„“ê²Œ ì—´ë¦¼)

íŠ¹ì„±:
  Wide Open (f/1.4 ~ f/2.8):
    - ë§ì€ ë¹› í†µê³¼
    - ì–•ì€ í”¼ì‚¬ê³„ ì‹¬ë„ (ë°°ê²½ íë¦¼)
    - í”Œë ˆì´ì–´ í´ë¡œì¦ˆì—…ì— ì í•©

  Mid Range (f/4 ~ f/5.6):
    - ê· í˜•ìˆëŠ” ë…¸ì¶œ
    - ì ì ˆí•œ ì‹¬ë„
    - ì¼ë°˜ì ì¸ ë°©ì†¡ ì„¤ì •

  Stopped Down (f/8 ~ f/16):
    - ì ì€ ë¹›
    - ê¹Šì€ í”¼ì‚¬ê³„ ì‹¬ë„ (ì „ì²´ ì´ˆì )
    - í…Œì´ë¸” ì „ì²´ ìƒ·ì— ì í•©
```

### ğŸ’¡ í¬ì»¤ ë°©ì†¡ ì‹¤ì „ ì„¤ì •

#### ìƒí™©ë³„ ë…¸ì¶œ ì„¤ì •
```python
class ExposureSettings:
    """í¬ì»¤ ë°©ì†¡ ìƒí™©ë³„ ë…¸ì¶œ ì„¤ì •"""

    def __init__(self):
        self.scenarios = {}

    def get_settings(self, scenario: str) -> dict:
        """ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì  ì„¤ì • ë°˜í™˜"""

        # 1. ì¼ë°˜ì ì¸ í…Œì´ë¸” ìƒ·
        if scenario == "table_wide":
            return {
                "iso": 800,
                "shutter": "1/50",  # 25fps * 2
                "aperture": "f/5.6",
                "rationale": "ì „ì²´ í…Œì´ë¸”ì— ê³ ë¥¸ ì´ˆì , ì ì ˆí•œ ë…¸ì´ì¦ˆ"
            }

        # 2. í”Œë ˆì´ì–´ í´ë¡œì¦ˆì—…
        elif scenario == "player_closeup":
            return {
                "iso": 400,
                "shutter": "1/50",
                "aperture": "f/2.8",
                "rationale": "ì–•ì€ ì‹¬ë„ë¡œ í”Œë ˆì´ì–´ ê°•ì¡°, ë°°ê²½ ë¸”ëŸ¬"
            }

        # 3. ì¹´ë“œ í´ë¡œì¦ˆì—… (RFID ì¹´ë©”ë¼)
        elif scenario == "card_detail":
            return {
                "iso": 200,
                "shutter": "1/100",  # ë¹ ë¥¸ ì¹´ë“œ ì›€ì§ì„
                "aperture": "f/4",
                "rationale": "ì¹´ë“œ ë””í…Œì¼ ì„ ëª…, ëª¨ì…˜ ë¸”ëŸ¬ ìµœì†Œí™”"
            }

        # 4. ì¹© ìŠ¤íƒ (ì €ì¡°ë„)
        elif scenario == "chip_stack_lowlight":
            return {
                "iso": 1600,
                "shutter": "1/50",
                "aperture": "f/2.0",
                "rationale": "í…Œì´ë¸” ì¡°ëª… ì•½í•œ êµ¬ì—­, ISO ìƒìŠ¹"
            }

        # 5. ìŠ¬ë¡œëª¨ì…˜ ë¦¬í”Œë ˆì´
        elif scenario == "slow_motion":
            return {
                "iso": 3200,
                "shutter": "1/200",  # 120fps * 1.6
                "aperture": "f/2.8",
                "rationale": "ê³ í”„ë ˆì„ ì´¬ì˜, ë¹ ë¥¸ ì…”í„° ë³´ìƒ"
            }

        return self._get_default_settings()

    def _get_default_settings(self) -> dict:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            "iso": 800,
            "shutter": "1/50",
            "aperture": "f/4",
            "rationale": "í‘œì¤€ ë°©ì†¡ ì„¤ì •"
        }

    def calculate_exposure_compensation(self, current, target) -> dict:
        """ë…¸ì¶œ ë³´ì • ê³„ì‚°"""

        # ISO ë³€ê²½ ì‹œ stops ê³„ì‚°
        iso_stops = math.log2(target["iso"] / current["iso"])

        # Shutter ë³€ê²½ ì‹œ stops ê³„ì‚°
        current_shutter_val = self._parse_shutter(current["shutter"])
        target_shutter_val = self._parse_shutter(target["shutter"])
        shutter_stops = math.log2(target_shutter_val / current_shutter_val)

        # Aperture ë³€ê²½ ì‹œ stops ê³„ì‚°
        current_f = self._parse_fstop(current["aperture"])
        target_f = self._parse_fstop(target["aperture"])
        aperture_stops = 2 * math.log2(target_f / current_f)

        total_stops = iso_stops + shutter_stops + aperture_stops

        return {
            "iso_stops": iso_stops,
            "shutter_stops": shutter_stops,
            "aperture_stops": aperture_stops,
            "total_stops": total_stops,
            "direction": "brighter" if total_stops > 0 else "darker"
        }
```

#### ë…¸ì¶œ ìë™ ì¡°ì • ì‹œìŠ¤í…œ
```python
import numpy as np
from PIL import Image

class AutoExposure:
    """ìë™ ë…¸ì¶œ ì¡°ì • ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.target_brightness = 0.45  # 0.0 ~ 1.0 (18% gray = 0.45)
        self.tolerance = 0.05

    def analyze_frame(self, frame: np.ndarray) -> dict:
        """í”„ë ˆì„ ë¶„ì„í•˜ì—¬ ë…¸ì¶œ ìƒíƒœ í‰ê°€"""

        # ë°ê¸° ë¶„ì„ (Luminance)
        if len(frame.shape) == 3:
            # RGB to Luminance (Rec.709)
            luminance = (0.2126 * frame[:,:,0] +
                        0.7152 * frame[:,:,1] +
                        0.0722 * frame[:,:,2])
        else:
            luminance = frame

        # í‰ê·  ë°ê¸°
        mean_brightness = np.mean(luminance) / 255.0

        # íˆìŠ¤í† ê·¸ë¨ ë¶„ì„
        histogram = np.histogram(luminance, bins=256, range=(0, 255))[0]

        # ê³¼ë‹¤/ê³¼ì†Œ ë…¸ì¶œ ê²€ì‚¬
        overexposed = np.sum(histogram[250:]) / luminance.size
        underexposed = np.sum(histogram[:5]) / luminance.size

        return {
            "mean_brightness": mean_brightness,
            "overexposed_ratio": overexposed,
            "underexposed_ratio": underexposed,
            "histogram": histogram,
            "status": self._evaluate_exposure(mean_brightness, overexposed, underexposed)
        }

    def _evaluate_exposure(self, brightness, over, under) -> str:
        """ë…¸ì¶œ ìƒíƒœ í‰ê°€"""
        if over > 0.05:
            return "overexposed"
        elif under > 0.10:
            return "underexposed"
        elif abs(brightness - self.target_brightness) < self.tolerance:
            return "optimal"
        elif brightness > self.target_brightness:
            return "slightly_bright"
        else:
            return "slightly_dark"

    def recommend_adjustment(self, analysis: dict, current_settings: dict) -> dict:
        """ë…¸ì¶œ ì¡°ì • ê¶Œì¥ì‚¬í•­"""

        status = analysis["status"]
        brightness = analysis["mean_brightness"]

        # ë°ê¸° ì°¨ì´ ê³„ì‚°
        delta = brightness - self.target_brightness
        stops_needed = -math.log2(1 + delta) if delta != 0 else 0

        # ìš°ì„ ìˆœìœ„: ISO > Aperture > Shutter (ë°©ì†¡ í‘œì¤€ ìœ ì§€)
        adjustment = {"changes": [], "priority": []}

        if abs(stops_needed) < 0.3:
            # ì‘ì€ ì¡°ì •: ISOë§Œ ë³€ê²½
            new_iso = int(current_settings["iso"] * (2 ** stops_needed))
            adjustment["changes"].append({
                "parameter": "iso",
                "current": current_settings["iso"],
                "recommended": new_iso,
                "reason": "Minor exposure adjustment"
            })

        elif abs(stops_needed) < 1.0:
            # ì¤‘ê°„ ì¡°ì •: ISO + Aperture
            iso_stops = stops_needed * 0.7
            aperture_stops = stops_needed * 0.3

            new_iso = int(current_settings["iso"] * (2 ** iso_stops))
            current_f = self._parse_fstop(current_settings["aperture"])
            new_f = current_f * (2 ** (aperture_stops / 2))

            adjustment["changes"].extend([
                {"parameter": "iso", "current": current_settings["iso"],
                 "recommended": new_iso},
                {"parameter": "aperture", "current": current_settings["aperture"],
                 "recommended": f"f/{new_f:.1f}"}
            ])

        else:
            # í° ì¡°ì •: ëª¨ë“  íŒŒë¼ë¯¸í„°
            adjustment["changes"].append({
                "warning": "Large exposure correction needed. Check lighting setup."
            })

        return adjustment
```

### ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

#### Waveform & Histogram ë¶„ì„
```python
import matplotlib.pyplot as plt

class ExposureMonitor:
    """ì‹¤ì‹œê°„ ë…¸ì¶œ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.history = []
        self.max_history = 300  # 10ì´ˆ @ 30fps

    def add_frame_analysis(self, analysis: dict):
        """í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ ì¶”ê°€"""
        self.history.append(analysis)
        if len(self.history) > self.max_history:
            self.history.pop(0)

    def generate_waveform(self, frame: np.ndarray):
        """Waveform ëª¨ë‹ˆí„° ìƒì„±"""
        height, width = frame.shape[:2]

        # ê° ìˆ˜í‰ ë¼ì¸ì˜ ë°ê¸° í”„ë¡œíŒŒì¼
        waveform = np.zeros((256, width))

        for x in range(width):
            column = frame[:, x]
            if len(column.shape) == 2:
                # RGB -> Luminance
                column = (0.2126 * column[:,0] +
                         0.7152 * column[:,1] +
                         0.0722 * column[:,2])

            hist, _ = np.histogram(column, bins=256, range=(0, 255))
            waveform[:, x] = hist

        return waveform

    def plot_exposure_trend(self):
        """ë…¸ì¶œ íŠ¸ë Œë“œ ê·¸ë˜í”„"""
        if len(self.history) < 10:
            return

        brightnesses = [h["mean_brightness"] for h in self.history]
        times = range(len(brightnesses))

        plt.figure(figsize=(12, 4))
        plt.plot(times, brightnesses, label="Mean Brightness")
        plt.axhline(y=0.45, color='g', linestyle='--', label="Target (18% gray)")
        plt.axhline(y=0.40, color='y', linestyle=':', label="Lower tolerance")
        plt.axhline(y=0.50, color='y', linestyle=':', label="Upper tolerance")
        plt.xlabel("Frame")
        plt.ylabel("Brightness (0-1)")
        plt.title("Exposure Trend (Last 10 seconds)")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        return plt
```

### ğŸ¯ ë°©ì†¡ í‘œì¤€ ê°€ì´ë“œë¼ì¸

#### GGPoker ë°©ì†¡ í‘œì¤€
```yaml
í‘œì¤€ ë…¸ì¶œ ì„¤ì •:
  ë©”ì¸ ì¹´ë©”ë¼ (í…Œì´ë¸”):
    ISO: 800
    Shutter: 1/50s (25fps)
    Aperture: f/5.6
    í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤: 3200K

  í´ë¡œì¦ˆì—… ì¹´ë©”ë¼:
    ISO: 400
    Shutter: 1/50s
    Aperture: f/2.8 ~ f/4
    í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤: 3200K

  ìŠ¬ë¡œëª¨ì…˜ ì¹´ë©”ë¼ (120fps):
    ISO: 3200
    Shutter: 1/240s
    Aperture: f/2.8
    í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤: 3200K

í—ˆìš© ë²”ìœ„:
  ISO ë²”ìœ„: 200 ~ 3200 (ë…¸ì´ì¦ˆ í—ˆìš© í•œê³„)
  Shutter: 1/50s ê³ ì • (180ë„ ì…”í„° ë£°)
  Aperture: f/2.0 ~ f/8.0

ê¸ˆì§€ ì‚¬í•­:
  - ISO 6400 ì´ìƒ (ê³¼ë„í•œ ë…¸ì´ì¦ˆ)
  - 1/25s ì´í•˜ ì…”í„° (ëª¨ì…˜ ë¸”ëŸ¬)
  - f/16 ì´ìƒ ì¡°ë¦¬ê°œ (íšŒì ˆ í˜„ìƒ)
```

---

<a name="3-white-balance"></a>
## 3ï¸âƒ£ White Balance (í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤)

### ğŸ“˜ ì •ì˜
**í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤**ëŠ” ì¡°ëª…ì˜ ìƒ‰ì˜¨ë„ë¥¼ ë³´ì •í•˜ì—¬ í°ìƒ‰ì´ ì‹¤ì œë¡œ í°ìƒ‰ìœ¼ë¡œ ë³´ì´ë„ë¡ ì¹´ë©”ë¼ì˜ ìƒ‰ìƒì„ ì¡°ì •í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì¼ˆë¹ˆ(K) ë‹¨ìœ„ë¡œ ì¸¡ì •ë˜ë©°, í¬ì»¤ ë°©ì†¡ì—ì„œëŠ” ì¼ê´€ëœ ìƒ‰ê° ìœ ì§€ë¥¼ ìœ„í•´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

### ğŸ”§ ìƒ‰ì˜¨ë„ ìŠ¤ì¼€ì¼

```yaml
ìƒ‰ì˜¨ë„ ì°¨íŠ¸:
  ì´›ë¶ˆ: 1,800K (ë§¤ìš° ë”°ëœ»í•œ ì˜¤ë Œì§€)
  ë°±ì—´ë“±: 2,700K ~ 3,000K (ë”°ëœ»í•œ ë…¸ë€ìƒ‰)
  í• ë¡œê²: 3,200K (í‘œì¤€ í……ìŠ¤í…)
  í˜•ê´‘ë“±: 4,000K ~ 5,000K (ì°¨ê°€ìš´ ë°±ìƒ‰)
  ìì—°ê´‘ (ë‚®): 5,500K ~ 6,500K (ì¤‘ì„± ë°±ìƒ‰)
  íë¦° ë‚ : 6,500K ~ 8,000K (ì°¨ê°€ìš´ ë¸”ë£¨)
  ê·¸ëŠ˜: 9,000K ~ 10,000K (ë§¤ìš° ì°¨ê°€ìš´ ë¸”ë£¨)

í¬ì»¤ ìŠ¤íŠœë””ì˜¤ í‘œì¤€:
  LED ìŠ¤íŠœë””ì˜¤ ì¡°ëª…: 3,200K (í……ìŠ¤í… ë§¤ì¹­)
  ê¶Œì¥ ì„¤ì •: 3,200K í”„ë¦¬ì…‹
  í—ˆìš© ë²”ìœ„: Â±200K (3,000K ~ 3,400K)
```

### ğŸ’¡ í¬ì»¤ í…Œì´ë¸” ì¡°ëª… ì„¤ì •

#### 3-Point Lighting Setup
```yaml
ì¡°ëª… êµ¬ì„±:
  Key Light (ì£¼ê´‘):
    ìœ„ì¹˜: í…Œì´ë¸” ì •ë©´ 45ë„, ë†’ì´ 2.5m
    ìƒ‰ì˜¨ë„: 3,200K
    ì¶œë ¥: 800W LED
    ì†Œí”„íŠ¸ë°•ìŠ¤: 120cm x 80cm
    ëª©ì : í…Œì´ë¸” ì „ì²´ ê¸°ë³¸ ì¡°ëª…

  Fill Light (ë³´ì¡°ê´‘):
    ìœ„ì¹˜: Key Light ë°˜ëŒ€í¸, ë‚®ì€ ê°•ë„
    ìƒ‰ì˜¨ë„: 3,200K (Keyì™€ ë™ì¼!)
    ì¶œë ¥: 400W LED
    ë””í“¨ì €: 90cm ì˜¥íƒ€ê³¤
    ëª©ì : ê·¸ë¦¼ì ë¶€ë“œëŸ½ê²Œ

  Back Light (ì—­ê´‘):
    ìœ„ì¹˜: í…Œì´ë¸” ë’¤ìª½, ë†’ì´ 3m
    ìƒ‰ì˜¨ë„: 3,400K (ì•½ê°„ ì°¨ê°‘ê²Œ)
    ì¶œë ¥: 300W LED
    ëª©ì : í”Œë ˆì´ì–´ ìœ¤ê³½ ê°•ì¡°

  Accent Light (í¬ì¸íŠ¸ ì¡°ëª…):
    ìœ„ì¹˜: ì¹© ìŠ¤íƒ, ì»¤ë®¤ë‹ˆí‹° ì¹´ë“œ ìœ„
    ìƒ‰ì˜¨ë„: 3,200K
    ì¶œë ¥: 150W LED ìŠ¤íŒŸ
    ëª©ì : ë””í…Œì¼ ê°•ì¡°
```

#### í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤ ì›Œí¬í”Œë¡œìš°
```python
class WhiteBalanceManager:
    """í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ê´€ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.preset_temps = {
            "tungsten": 3200,
            "fluorescent": 4000,
            "daylight": 5600,
            "cloudy": 6500,
            "shade": 7500,
            "custom": None
        }

        self.current_setting = "tungsten"
        self.custom_kelvin = 3200

    def set_white_balance(self, camera_id: str, method: str):
        """í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì„¤ì •"""

        if method == "auto":
            # ìë™ í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ (AWB)
            return self._set_awb(camera_id)

        elif method == "preset":
            # í”„ë¦¬ì…‹ ì‚¬ìš© (3200K)
            return self._set_preset(camera_id, self.current_setting)

        elif method == "custom":
            # ì»¤ìŠ¤í…€ ì¼ˆë¹ˆ ê°’
            return self._set_custom_kelvin(camera_id, self.custom_kelvin)

        elif method == "grey_card":
            # ê·¸ë ˆì´ ì¹´ë“œ ê¸°ì¤€
            return self._calibrate_grey_card(camera_id)

    def _calibrate_grey_card(self, camera_id: str) -> dict:
        """18% ê·¸ë ˆì´ ì¹´ë“œë¥¼ ì´ìš©í•œ ì •ë°€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜"""

        # 1ë‹¨ê³„: ê·¸ë ˆì´ ì¹´ë“œ ì´¬ì˜
        print(f"[{camera_id}] Place 18% grey card in center of table")
        print("Ensure even lighting across the card")
        input("Press Enter when ready...")

        # 2ë‹¨ê³„: í”„ë ˆì„ ìº¡ì²˜
        frame = self._capture_frame(camera_id)

        # 3ë‹¨ê³„: ê·¸ë ˆì´ ì¹´ë“œ ì˜ì—­ ì¶”ì¶œ (ì¤‘ì•™ 10%)
        h, w = frame.shape[:2]
        center_region = frame[
            int(h*0.45):int(h*0.55),
            int(w*0.45):int(w*0.55)
        ]

        # 4ë‹¨ê³„: RGB í‰ê·  ê³„ì‚°
        r_avg = np.mean(center_region[:,:,0])
        g_avg = np.mean(center_region[:,:,1])
        b_avg = np.mean(center_region[:,:,2])

        # 5ë‹¨ê³„: ìƒ‰ì˜¨ë„ ì¶”ì •
        color_temp = self._estimate_color_temp(r_avg, g_avg, b_avg)

        # 6ë‹¨ê³„: í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ê²Œì¸ ê³„ì‚°
        wb_gains = {
            "red_gain": g_avg / r_avg,
            "green_gain": 1.0,
            "blue_gain": g_avg / b_avg
        }

        # 7ë‹¨ê³„: ì¹´ë©”ë¼ì— ì ìš©
        self._apply_wb_gains(camera_id, wb_gains)

        return {
            "method": "grey_card_calibration",
            "estimated_color_temp": color_temp,
            "wb_gains": wb_gains,
            "rgb_averages": {"r": r_avg, "g": g_avg, "b": b_avg}
        }

    def _estimate_color_temp(self, r: float, g: float, b: float) -> int:
        """RGB ê°’ìœ¼ë¡œ ìƒ‰ì˜¨ë„ ì¶”ì •"""

        # McCamy's ê³µì‹ (ê·¼ì‚¬ì¹˜)
        n = (r - b) / (g - b) if (g - b) != 0 else 0
        CCT = 437 * (n**3) + 3601 * (n**2) + 6861 * n + 5517

        return int(CCT)

    def match_cameras(self, camera_ids: list) -> dict:
        """ì—¬ëŸ¬ ì¹´ë©”ë¼ì˜ í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¼ì¹˜ì‹œí‚¤ê¸°"""

        # 1ë‹¨ê³„: ë§ˆìŠ¤í„° ì¹´ë©”ë¼ ì„ ì • (ë³´í†µ ë©”ì¸ ì¹´ë©”ë¼)
        master_camera = camera_ids[0]

        # 2ë‹¨ê³„: ë§ˆìŠ¤í„° ì¹´ë©”ë¼ë¡œ ê·¸ë ˆì´ ì¹´ë“œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
        master_wb = self._calibrate_grey_card(master_camera)

        # 3ë‹¨ê³„: ë‹¤ë¥¸ ì¹´ë©”ë¼ë“¤ì— ë™ì¼í•œ ì„¤ì • ì ìš©
        results = {master_camera: master_wb}

        for camera_id in camera_ids[1:]:
            result = self._apply_wb_gains(
                camera_id,
                master_wb["wb_gains"]
            )
            results[camera_id] = result

        # 4ë‹¨ê³„: ê²€ì¦
        verification = self._verify_wb_match(camera_ids)

        return {
            "master_camera": master_camera,
            "master_wb": master_wb,
            "slave_results": results,
            "verification": verification
        }

    def _verify_wb_match(self, camera_ids: list) -> dict:
        """ì¹´ë©”ë¼ ê°„ í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¼ì¹˜ ê²€ì¦"""

        # ê° ì¹´ë©”ë¼ì—ì„œ ë™ì¼í•œ ê·¸ë ˆì´ ì¹´ë“œ ì´¬ì˜
        frames = {cam: self._capture_frame(cam) for cam in camera_ids}

        # RGB í‰ê·  ê³„ì‚°
        rgb_values = {}
        for cam, frame in frames.items():
            h, w = frame.shape[:2]
            center = frame[int(h*0.45):int(h*0.55), int(w*0.45):int(w*0.55)]
            rgb_values[cam] = {
                "r": np.mean(center[:,:,0]),
                "g": np.mean(center[:,:,1]),
                "b": np.mean(center[:,:,2])
            }

        # í¸ì°¨ ê³„ì‚°
        master_rgb = rgb_values[camera_ids[0]]
        deviations = {}

        for cam in camera_ids[1:]:
            cam_rgb = rgb_values[cam]
            deviations[cam] = {
                "r_dev": abs(cam_rgb["r"] - master_rgb["r"]),
                "g_dev": abs(cam_rgb["g"] - master_rgb["g"]),
                "b_dev": abs(cam_rgb["b"] - master_rgb["b"]),
                "total_dev": np.sqrt(
                    (cam_rgb["r"] - master_rgb["r"])**2 +
                    (cam_rgb["g"] - master_rgb["g"])**2 +
                    (cam_rgb["b"] - master_rgb["b"])**2
                )
            }

        # í—ˆìš© ë²”ìœ„: ì´ í¸ì°¨ < 10 (8-bit ê¸°ì¤€)
        all_matched = all(d["total_dev"] < 10 for d in deviations.values())

        return {
            "all_cameras_matched": all_matched,
            "rgb_values": rgb_values,
            "deviations": deviations
        }
```

### ğŸ“Š ìƒ‰ì˜¨ë„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
import cv2

class ColorTempMonitor:
    """ì‹¤ì‹œê°„ ìƒ‰ì˜¨ë„ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.target_temp = 3200
        self.tolerance = 200  # Â±200K
        self.history = []

    def analyze_frame_color(self, frame: np.ndarray) -> dict:
        """í”„ë ˆì„ì˜ ìƒ‰ì˜¨ë„ ë¶„ì„"""

        # RGB ì±„ë„ í‰ê· 
        r_mean = np.mean(frame[:,:,0])
        g_mean = np.mean(frame[:,:,1])
        b_mean = np.mean(frame[:,:,2])

        # ìƒ‰ì˜¨ë„ ì¶”ì •
        estimated_temp = self._rgb_to_color_temp(r_mean, g_mean, b_mean)

        # Color Cast ê²€ì‚¬
        color_cast = self._detect_color_cast(r_mean, g_mean, b_mean)

        # ìƒ‰ì˜¨ë„ í¸ì°¨
        temp_deviation = estimated_temp - self.target_temp

        return {
            "estimated_temp": estimated_temp,
            "target_temp": self.target_temp,
            "deviation_kelvin": temp_deviation,
            "within_tolerance": abs(temp_deviation) < self.tolerance,
            "color_cast": color_cast,
            "rgb_means": {"r": r_mean, "g": g_mean, "b": b_mean}
        }

    def _detect_color_cast(self, r, g, b) -> str:
        """Color Cast (ìƒ‰í¸í–¥) ê²€ì¶œ"""

        # ì •ê·œí™”
        total = r + g + b
        r_norm = r / total
        g_norm = g / total
        b_norm = b / total

        # ê¸°ì¤€ê°’ (ê· í˜• ì¡íŒ ë°±ìƒ‰)
        neutral = 1/3
        threshold = 0.02

        if r_norm > neutral + threshold:
            return "warm_cast"  # ë”°ëœ»í•œ í¸í–¥ (ì˜¤ë Œì§€/ë ˆë“œ)
        elif b_norm > neutral + threshold:
            return "cool_cast"  # ì°¨ê°€ìš´ í¸í–¥ (ë¸”ë£¨)
        elif g_norm > neutral + threshold:
            return "green_cast"  # ë…¹ìƒ‰ í¸í–¥ (í˜•ê´‘ë“±)
        else:
            return "neutral"  # ì¤‘ì„±

    def generate_color_chart(self, frame: np.ndarray):
        """ì»¬ëŸ¬ ì²´í¬ ì°¨íŠ¸ ìƒì„±"""

        # 9êµ¬ì—­ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì˜ì—­ì˜ ìƒ‰ì˜¨ë„ ë¶„ì„
        h, w = frame.shape[:2]
        grid_h, grid_w = h // 3, w // 3

        color_map = np.zeros((3, 3))

        for i in range(3):
            for j in range(3):
                region = frame[
                    i*grid_h:(i+1)*grid_h,
                    j*grid_w:(j+1)*grid_w
                ]

                r = np.mean(region[:,:,0])
                g = np.mean(region[:,:,1])
                b = np.mean(region[:,:,2])

                color_map[i, j] = self._rgb_to_color_temp(r, g, b)

        return color_map
```

### ğŸ¯ ì‹¤ì „ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### ë¬¸ì œ 1: ì¹´ë©”ë¼ ê°„ ìƒ‰ê° ë¶ˆì¼ì¹˜
```markdown
ì¦ìƒ: ê°™ì€ í…Œì´ë¸”ì„ ì´¬ì˜í•˜ëŠ”ë° ì¹´ë©”ë¼ë§ˆë‹¤ ìƒ‰ê°ì´ ë‹¤ë¦„

ì›ì¸:
- ì¹´ë©”ë¼ë³„ë¡œ Auto White Balance (AWB) ì‚¬ìš©
- ê° ì¹´ë©”ë¼ê°€ ë‹¤ë¥¸ ì˜ì—­ì„ ê¸°ì¤€ìœ¼ë¡œ ìë™ ë³´ì •
- ì¡°ëª… ë³€í™”ì— ë”°ë¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ë™

í•´ê²°:
1. ëª¨ë“  ì¹´ë©”ë¼ë¥¼ Manual White Balanceë¡œ ë³€ê²½
2. ê·¸ë ˆì´ ì¹´ë“œë¥¼ ì´ìš©í•´ ë§ˆìŠ¤í„° ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
3. ë§ˆìŠ¤í„° ì¹´ë©”ë¼ì˜ Kelvin ê°’ì„ ë‹¤ë¥¸ ì¹´ë©”ë¼ì— ë³µì‚¬
4. ì£¼ê¸°ì ìœ¼ë¡œ ì¬ê²€ì¦ (2ì‹œê°„ë§ˆë‹¤)

Python ìë™í™”:
```python
# ëª¨ë“  ì¹´ë©”ë¼ë¥¼ 3200Kë¡œ ê³ ì •
for camera in all_cameras:
    camera.set_white_balance_mode("manual")
    camera.set_color_temp_kelvin(3200)
    camera.disable_auto_white_balance()
```
```

#### ë¬¸ì œ 2: ì‹œê°„ì— ë”°ë¥¸ ìƒ‰ì˜¨ë„ ë³€í™”
```markdown
ì¦ìƒ: ë°©ì†¡ ì´ˆë°˜ê³¼ í›„ë°˜ì˜ ìƒ‰ê°ì´ ë‹¤ë¦„

ì›ì¸:
- LED ì¡°ëª…ì˜ ì˜¨ë„ ìƒìŠ¹ì— ë”°ë¥¸ ìƒ‰ì˜¨ë„ ë³€í™”
- í˜•ê´‘ë“±ì˜ ê²½ë…„ ë³€í™”
- ì™¸ë¶€ ìì—°ê´‘ ìœ ì… (ì°½ë¬¸)

í•´ê²°:
1. ì¡°ëª… Pre-heating (ì´¬ì˜ 1ì‹œê°„ ì „ ì¼œê¸°)
2. ì°½ë¬¸ ì™„ì „ ì°¨ë‹¨ (ë¸”ë™ì•„ì›ƒ ì»¤íŠ¼)
3. ì¡°ëª… ìƒ‰ì˜¨ë„ ëª¨ë‹ˆí„°ë§
4. í•„ìš”ì‹œ ì¤‘ê°„ ì¬ìº˜ë¦¬ë¸Œë ˆì´ì…˜

ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸:
```python
def continuous_wb_monitoring():
    """ì—°ì† í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ëª¨ë‹ˆí„°ë§"""

    while True:
        for camera in all_cameras:
            analysis = analyze_frame_color(camera.get_frame())

            if not analysis["within_tolerance"]:
                alert = f"Camera {camera.id}: Color temp drift detected!"
                alert += f"\nTarget: {analysis['target_temp']}K"
                alert += f"\nCurrent: {analysis['estimated_temp']}K"
                alert += f"\nDeviation: {analysis['deviation_kelvin']}K"

                send_alert_to_td(alert)

                # ìë™ ì¬ì¡°ì •
                recalibrate_camera(camera.id)

        time.sleep(120)  # 2ë¶„ë§ˆë‹¤ ì²´í¬
```
```

---

<a name="4-focus-pulling"></a>
## 4ï¸âƒ£ Focus Pulling (í¬ì»¤ìŠ¤ í’€ë§)

### ğŸ“˜ ì •ì˜
**í¬ì»¤ìŠ¤ í’€ë§**ì€ ì´¬ì˜ ì¤‘ í”¼ì‚¬ì²´ì˜ ì›€ì§ì„ì´ë‚˜ êµ¬ë„ ë³€ê²½ì— ë”°ë¼ ì´ˆì ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì˜í™” ë° ë°©ì†¡ì—ì„œ í”¼ì‚¬ê³„ ì‹¬ë„(DOF)ê°€ ì–•ì„ ë•Œ íŠ¹íˆ ì¤‘ìš”í•˜ë©°, í¬ì»¤ ë°©ì†¡ì—ì„œëŠ” ì¹´ë“œ ê³µê°œë‚˜ í”Œë ˆì´ì–´ ë¦¬ì•¡ì…˜ ì´¬ì˜ ì‹œ í™œìš©ë©ë‹ˆë‹¤.

### ğŸ”§ ê¸°ìˆ  ì›ë¦¬

#### Depth of Field (í”¼ì‚¬ê³„ ì‹¬ë„)
```yaml
ì •ì˜: ì„ ëª…í•œ ì´ˆì ì´ ìœ ì§€ë˜ëŠ” í”¼ì‚¬ì²´ ì•ë’¤ì˜ ê±°ë¦¬ ë²”ìœ„

ì˜í–¥ ìš”ì†Œ:
  1. ì¡°ë¦¬ê°œ (Aperture):
     Wide (f/1.4): ë§¤ìš° ì–•ì€ DOF (ë°°ê²½ ì™„ì „ ë¸”ëŸ¬)
     Narrow (f/16): ë§¤ìš° ê¹Šì€ DOF (ì „ì²´ ì„ ëª…)

  2. ì´ˆì  ê±°ë¦¬ (Focal Length):
     Wide (24mm): ê¹Šì€ DOF
     Telephoto (200mm): ì–•ì€ DOF

  3. í”¼ì‚¬ì²´ ê±°ë¦¬:
     Close (1m): ì–•ì€ DOF
     Far (10m): ê¹Šì€ DOF

  4. ì„¼ì„œ í¬ê¸°:
     Full Frame (36x24mm): ì–•ì€ DOF
     Micro 4/3 (17x13mm): ê¹Šì€ DOF

ê³„ì‚°ì‹:
  DOF = (2 * N * C * sÂ²) / fÂ²

  N = f-stop (ì¡°ë¦¬ê°œ ê°’)
  C = Circle of Confusion (0.03mm for Full Frame)
  s = í”¼ì‚¬ì²´ ê±°ë¦¬
  f = ì´ˆì  ê±°ë¦¬
```

#### í¬ì»¤ ë°©ì†¡ DOF ì „ëµ
```python
class DepthOfFieldCalculator:
    """í”¼ì‚¬ê³„ ì‹¬ë„ ê³„ì‚°ê¸°"""

    def __init__(self):
        # ì„¼ì„œ í¬ê¸° (mm)
        self.sensor_sizes = {
            "full_frame": (36, 24),
            "aps_c": (23.6, 15.7),
            "micro_43": (17.3, 13.0)
        }

        # Circle of Confusion (mm)
        self.coc_values = {
            "full_frame": 0.030,
            "aps_c": 0.019,
            "micro_43": 0.015
        }

    def calculate_dof(self, focal_length_mm: float, f_stop: float,
                     subject_distance_m: float, sensor_type: str = "full_frame") -> dict:
        """í”¼ì‚¬ê³„ ì‹¬ë„ ê³„ì‚°"""

        f = focal_length_mm
        N = f_stop
        s = subject_distance_m * 1000  # m to mm
        C = self.coc_values[sensor_type]

        # Hyperfocal Distance
        H = (f**2) / (N * C) + f

        # Near Focus Distance
        if s < H:
            D_n = (s * (H - f)) / (H + s - 2*f)
        else:
            D_n = s / 2

        # Far Focus Distance
        if s < H:
            D_f = (s * (H - f)) / (H - s)
        else:
            D_f = float('inf')

        # Total DOF
        DOF = D_f - D_n

        return {
            "focal_length_mm": f,
            "f_stop": N,
            "subject_distance_m": s / 1000,
            "sensor_type": sensor_type,
            "hyperfocal_distance_m": H / 1000,
            "near_focus_m": D_n / 1000,
            "far_focus_m": D_f / 1000 if D_f != float('inf') else "Infinity",
            "total_dof_m": DOF / 1000 if DOF != float('inf') else "Infinity",
            "dof_in_front_m": (s - D_n) / 1000,
            "dof_behind_m": (D_f - s) / 1000 if D_f != float('inf') else "Infinity"
        }

    def poker_preset_dof(self, shot_type: str) -> dict:
        """í¬ì»¤ ë°©ì†¡ í‘œì¤€ ìƒ·ë³„ DOF"""

        presets = {
            "table_wide": {
                "focal_length": 24,
                "f_stop": 5.6,
                "distance": 3.0,
                "description": "ì „ì²´ í…Œì´ë¸”, ëª¨ë“  í”Œë ˆì´ì–´ ì„ ëª…"
            },
            "player_medium": {
                "focal_length": 50,
                "f_stop": 4.0,
                "distance": 2.0,
                "description": "í”Œë ˆì´ì–´ í´ë¡œì¦ˆì—…, ë°°ê²½ ì•½ê°„ ë¸”ëŸ¬"
            },
            "player_tight": {
                "focal_length": 85,
                "f_stop": 2.8,
                "distance": 1.5,
                "description": "í”Œë ˆì´ì–´ ì–¼êµ´, ë°°ê²½ ì™„ì „ ë¸”ëŸ¬"
            },
            "card_detail": {
                "focal_length": 100,
                "f_stop": 4.0,
                "distance": 0.5,
                "description": "ì¹´ë“œ í´ë¡œì¦ˆì—…, í…ìŠ¤íŠ¸ ì„ ëª…"
            },
            "chip_stack": {
                "focal_length": 85,
                "f_stop": 5.6,
                "distance": 1.0,
                "description": "ì¹© ìŠ¤íƒ ì „ì²´ ì„ ëª…"
            }
        }

        if shot_type not in presets:
            return {"error": "Unknown shot type"}

        preset = presets[shot_type]
        dof = self.calculate_dof(
            preset["focal_length"],
            preset["f_stop"],
            preset["distance"]
        )

        dof["shot_type"] = shot_type
        dof["description"] = preset["description"]

        return dof
```

### ğŸ’¡ ìë™ í¬ì»¤ìŠ¤ vs ìˆ˜ë™ í¬ì»¤ìŠ¤

#### ìë™ í¬ì»¤ìŠ¤ (AF) ì‹œìŠ¤í…œ
```yaml
AF ëª¨ë“œ:
  1. AF-S (Single AF):
     - ë°˜ì…”í„°ë¡œ ì´ˆì  ê³ ì •
     - ì •ì  í”¼ì‚¬ì²´
     - í¬ì»¤ í…Œì´ë¸” ì „ì²´ ìƒ·

  2. AF-C (Continuous AF):
     - í”¼ì‚¬ì²´ ì¶”ì 
     - ì›€ì§ì´ëŠ” í”Œë ˆì´ì–´
     - ì¹´ë“œ ë°°ë¶„ ì¥ë©´

  3. AF-A (Auto AF):
     - ìƒí™© ìë™ íŒë‹¨
     - ë¹„ì¶”ì²œ (ì˜ˆì¸¡ ë¶ˆê°€)

AF ì˜ì—­:
  - Wide Area: ì „ì²´ í…Œì´ë¸”
  - Zone Area: íŠ¹ì • êµ¬ì—­ (í”Œë ˆì´ì–´ Zone)
  - Center Point: ì¤‘ì•™ ì§‘ì¤‘
  - Face Detection: í”Œë ˆì´ì–´ ì–¼êµ´
  - Eye AF: í”Œë ˆì´ì–´ ëˆˆ (Î±7 series)

í¬ì»¤ ë°©ì†¡ ê¶Œì¥:
  ì¼ë°˜ ìƒ·: AF-S + Face Detection
  ì•¡ì…˜ ìƒ·: AF-C + Zone Area
  í´ë¡œì¦ˆì—…: Manual Focus (ì •ë°€ ì œì–´)
```

#### ìˆ˜ë™ í¬ì»¤ìŠ¤ í’€ë§ ì‹œìŠ¤í…œ
```python
import time
import math

class FocusPuller:
    """ìˆ˜ë™ í¬ì»¤ìŠ¤ í’€ë§ ì‹œìŠ¤í…œ"""

    def __init__(self, camera_controller):
        self.camera = camera_controller
        self.focus_marks = {}  # ì´ˆì  ë§ˆí¬ ì €ì¥
        self.current_focus = 0.5  # 0.0 (near) ~ 1.0 (far)
        self.transition_speed = 0.05  # ì „í™˜ ì†ë„

    def set_focus_mark(self, mark_name: str, focus_value: float):
        """ì´ˆì  ë§ˆí¬ ì„¤ì • (ë¦¬í—ˆì„¤ ì¤‘)"""
        self.focus_marks[mark_name] = focus_value
        print(f"Focus mark '{mark_name}' set at {focus_value:.3f}")

    def pull_focus(self, from_mark: str, to_mark: str, duration_sec: float):
        """ë‘ ì´ˆì  ë§ˆí¬ ì‚¬ì´ë¥¼ ë¶€ë“œëŸ½ê²Œ ì „í™˜"""

        if from_mark not in self.focus_marks or to_mark not in self.focus_marks:
            raise ValueError("Focus marks not found")

        start_focus = self.focus_marks[from_mark]
        end_focus = self.focus_marks[to_mark]

        # ì „í™˜ ê³¡ì„  (Ease In-Out)
        steps = int(duration_sec / 0.033)  # 30fps ê¸°ì¤€

        for step in range(steps + 1):
            # Ease In-Out ê³¡ì„ 
            t = step / steps
            t_eased = self._ease_in_out(t)

            # í˜„ì¬ ì´ˆì  ê°’
            current = start_focus + (end_focus - start_focus) * t_eased

            # ì¹´ë©”ë¼ì— ì ìš©
            self.camera.set_focus_position(current)
            self.current_focus = current

            time.sleep(0.033)

    def _ease_in_out(self, t: float) -> float:
        """Ease In-Out ê³¡ì„  (ë¶€ë“œëŸ¬ìš´ ê°€ì†/ê°ì†)"""
        if t < 0.5:
            return 2 * t * t
        else:
            return 1 - math.pow(-2 * t + 2, 2) / 2

    def setup_poker_focus_marks(self):
        """í¬ì»¤ í…Œì´ë¸” í‘œì¤€ ì´ˆì  ë§ˆí¬ ì„¤ì •"""

        # ë¦¬í—ˆì„¤: ê° ìœ„ì¹˜ì— ì´ˆì  ë§ì¶”ê³  ì €ì¥
        marks = {
            "dealer": 0.45,       # ë”œëŸ¬ ìœ„ì¹˜
            "player_1": 0.50,     # í”Œë ˆì´ì–´ 1ë²ˆ (BTN)
            "player_2": 0.52,
            "player_3": 0.55,
            "player_4": 0.58,
            "player_5": 0.60,
            "player_6": 0.58,
            "player_7": 0.55,
            "player_8": 0.52,
            "community_cards": 0.47,  # ì»¤ë®¤ë‹ˆí‹° ì¹´ë“œ
            "pot": 0.48              # íŒŸ (ì¤‘ì•™)
        }

        for mark_name, focus_val in marks.items():
            self.set_focus_mark(mark_name, focus_val)

        print("Poker table focus marks configured")

    def execute_focus_sequence(self, sequence: list):
        """ì´ˆì  ì‹œí€€ìŠ¤ ì‹¤í–‰"""

        for action in sequence:
            mark_from = action["from"]
            mark_to = action["to"]
            duration = action["duration"]
            pause = action.get("pause", 0)

            print(f"Focus pulling: {mark_from} â†’ {mark_to} ({duration}s)")
            self.pull_focus(mark_from, mark_to, duration)

            if pause > 0:
                time.sleep(pause)
```

#### í¬ì»¤ ë°©ì†¡ í¬ì»¤ìŠ¤ ì‹œí€€ìŠ¤ ì˜ˆì‹œ
```python
# ì˜¬ì¸ ìƒí™© í¬ì»¤ìŠ¤ ì‹œí€€ìŠ¤
all_in_focus_sequence = [
    {
        "from": "player_3",
        "to": "pot",
        "duration": 1.5,
        "pause": 2.0,
        "description": "ì˜¬ì¸ ì„ ì–¸ â†’ íŒŸìœ¼ë¡œ ì´ˆì "
    },
    {
        "from": "pot",
        "to": "player_7",
        "duration": 1.0,
        "pause": 3.0,
        "description": "íŒŸ â†’ ìƒëŒ€ í”Œë ˆì´ì–´ ë¦¬ì•¡ì…˜"
    },
    {
        "from": "player_7",
        "to": "community_cards",
        "duration": 1.2,
        "pause": 0,
        "description": "í”Œë ˆì´ì–´ â†’ ì»¤ë®¤ë‹ˆí‹° ì¹´ë“œ (ë¦¬ë²„ ëŒ€ê¸°)"
    }
]

# ì‹¤í–‰
focus_puller = FocusPuller(camera_controller)
focus_puller.setup_poker_focus_marks()
focus_puller.execute_focus_sequence(all_in_focus_sequence)
```

### ğŸ¯ ì‹¤ì „ ê¸°ë²•

#### Rack Focus (ë˜í¬ í¬ì»¤ìŠ¤)
```markdown
ì •ì˜: í•œ í”¼ì‚¬ì²´ì—ì„œ ë‹¤ë¥¸ í”¼ì‚¬ì²´ë¡œ ì´ˆì ì„ ë¹ ë¥´ê²Œ ì „í™˜í•˜ì—¬ ì‹œì„ ì„ ìœ ë„í•˜ëŠ” ê¸°ë²•

í¬ì»¤ ë°©ì†¡ í™œìš©:
1. í”Œë ˆì´ì–´ â†’ ìƒëŒ€ í”Œë ˆì´ì–´
   - ë² íŒ… ì•¡ì…˜ í›„ ìƒëŒ€ ë¦¬ì•¡ì…˜
   - Duration: 0.8 ~ 1.2ì´ˆ

2. í”Œë ˆì´ì–´ â†’ ì»¤ë®¤ë‹ˆí‹° ì¹´ë“œ
   - í”Œë ˆì´ì–´ í‘œì • â†’ ì¹´ë“œ ê³µê°œ
   - Duration: 1.0 ~ 1.5ì´ˆ

3. ì¹© ìŠ¤íƒ â†’ í”Œë ˆì´ì–´ ì–¼êµ´
   - ì˜¬ì¸ ì¹© â†’ í”Œë ˆì´ì–´ ê¸´ì¥ê°
   - Duration: 1.5 ~ 2.0ì´ˆ

ì£¼ì˜ì‚¬í•­:
- ë„ˆë¬´ ë¹ ë¥´ë©´ ì‹œì²­ì í˜¼ë€
- ë„ˆë¬´ ëŠë¦¬ë©´ ì§€ë£¨í•¨
- ìµœì : 1.0 ~ 1.5ì´ˆ (ë¶€ë“œëŸ¬ìš´ ì „í™˜)
```

#### Follow Focus (íŒ”ë¡œìš° í¬ì»¤ìŠ¤)
```markdown
ì •ì˜: ì›€ì§ì´ëŠ” í”¼ì‚¬ì²´ë¥¼ ë”°ë¼ê°€ë©° ì´ˆì ì„ ìœ ì§€í•˜ëŠ” ê¸°ë²•

í¬ì»¤ ë°©ì†¡ í™œìš©:
1. ì¹´ë“œ ë°°ë¶„ ì¥ë©´
   - ë”œëŸ¬ ì† â†’ í”Œë ˆì´ì–´ ì•
   - ì—°ì† ì´ˆì  ì¶”ì 

2. ì¹© í‘¸ì‹œ
   - í”Œë ˆì´ì–´ ì¹© â†’ ì¤‘ì•™ íŒŸ
   - ì›€ì§ì„ì— ë§ì¶˜ ì´ˆì 

3. í”Œë ˆì´ì–´ ì´ë™
   - ìë¦¬ ì´ë™, ìŠ¤íŠ¸ë ˆì¹­
   - AF-C ëª¨ë“œ í™œìš©
```

### ğŸ“Š Focus Peaking í™œìš©
```python
class FocusPeakingOverlay:
    """Focus Peaking ì‹¤ì‹œê°„ ì˜¤ë²„ë ˆì´"""

    def __init__(self):
        self.peak_color = (0, 255, 0)  # ë…¹ìƒ‰
        self.threshold = 100

    def generate_overlay(self, frame: np.ndarray) -> np.ndarray:
        """ì´ˆì  ë§ì€ ì˜ì—­ í•˜ì´ë¼ì´íŠ¸ ìƒì„±"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, self.threshold, self.threshold * 2)

        overlay = frame.copy()
        overlay[edges > 0] = self.peak_color

        return cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
```

---

## Section 2: ì˜ìƒ ì‹ í˜¸ ë° í‘œì¤€

<a name="6-sdi-signal"></a>
## 6ï¸âƒ£ SDI (Serial Digital Interface)

### ğŸ“˜ ì •ì˜
**SDI**ëŠ” ë°©ì†¡ìš© ë¹„ë””ì˜¤ ë° ì˜¤ë””ì˜¤ë¥¼ ë””ì§€í„¸ ì§ë ¬ ì‹ í˜¸ë¡œ ì „ì†¡í•˜ëŠ” í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. SMPTEì— ì˜í•´ ì •ì˜ë˜ì—ˆìœ¼ë©°, í”„ë¡œí˜ì…”ë„ ë°©ì†¡ í™˜ê²½ì—ì„œ ì‚¬ì‹¤ìƒì˜ í‘œì¤€ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.

### ğŸ”§ SDI ê·œê²©

#### SDI ì„¸ëŒ€ë³„ ê·œê²©
```yaml
SD-SDI (SMPTE 259M):
  í•´ìƒë„: 480i/576i
  ë¹„íŠ¸ë ˆì´íŠ¸: 270 Mbps
  ì¼€ì´ë¸”: BNC, 75Î©
  ìµœëŒ€ ê±°ë¦¬: 300m (Belden 1694A)
  ìƒíƒœ: Legacy (ë ˆê±°ì‹œ)

HD-SDI (SMPTE 292M):
  í•´ìƒë„: 1080i/1080p, 720p
  ë¹„íŠ¸ë ˆì´íŠ¸: 1.485 Gbps, 1.485/1.001 Gbps
  ì¼€ì´ë¸”: BNC, 75Î©
  ìµœëŒ€ ê±°ë¦¬: 100m (1080p60)
  ì‚¬ìš©: í˜„ì¬ ë°©ì†¡ í‘œì¤€

3G-SDI (SMPTE 424M):
  í•´ìƒë„: 1080p60, 2K
  ë¹„íŠ¸ë ˆì´íŠ¸: 2.97 Gbps, 2.97/1.001 Gbps
  ë ˆë²¨:
    - Level A: ë‹¨ì¼ ë§í¬ (1080p60)
    - Level B: ë“€ì–¼ ë§í¬ í˜¸í™˜ (ë‘ ê°œì˜ 1.5G)
  ìµœëŒ€ ê±°ë¦¬: 100m
  ì‚¬ìš©: HD ê³ í”„ë ˆì„, 2K

6G-SDI (SMPTE ST-2081):
  í•´ìƒë„: 1080p120, 4K30
  ë¹„íŠ¸ë ˆì´íŠ¸: 6 Gbps
  ìµœëŒ€ ê±°ë¦¬: 75m
  ì‚¬ìš©: 4K30, HFR HD

12G-SDI (SMPTE ST-2082):
  í•´ìƒë„: 4K60 (4096x2160)
  ë¹„íŠ¸ë ˆì´íŠ¸: 12 Gbps
  ìµœëŒ€ ê±°ë¦¬: 70m (ë‹¨ì¼ ì¼€ì´ë¸”)
  ì‚¬ìš©: 4K60 í”„ë¡œë•ì…˜ (í˜„ì¬ ìµœê³  ê·œê²©)
```

#### í¬ì»¤ ë°©ì†¡ SDI êµ¬ì„±
```yaml
GGPoker í”„ë¡œë•ì…˜ í‘œì¤€:
  ì¹´ë©”ë¼ ì¶œë ¥: 3G-SDI (1080p50)
  ìŠ¤ìœ„ì²˜ ì…ë ¥: 3G-SDI
  ìŠ¤ìœ„ì²˜ ì¶œë ¥ (PGM): 12G-SDI (4K50 ì—…ìŠ¤ì¼€ì¼)
  ë ˆì½”ë” ì…ë ¥: 12G-SDI
  ëª¨ë‹ˆí„° ì¶œë ¥: 3G-SDI / HDMI

ì¼€ì´ë¸” êµ¬ì„±:
  ì¹´ë©”ë¼ â†’ ìŠ¤ìœ„ì²˜: Belden 1855A (3G/6G/12G ì§€ì›)
  ê¸¸ì´: í‰ê·  50m
  ì»¤ë„¥í„°: Canare BCP-C77 (75Î© BNC)

ë¦¬ë˜ë˜ì‹œ:
  ì£¼ ì‹ í˜¸: SDI
  ë°±ì—…: NDI over IP (10GbE)
```

### ğŸ’¡ SDI ì‹ í˜¸ ë¶„ì„

#### SDI Eye Pattern ë¶„ì„
```python
class SDIAnalyzer:
    """SDI ì‹ í˜¸ í’ˆì§ˆ ë¶„ì„ê¸°"""

    def __init__(self, sdi_input_device):
        self.device = sdi_input_device
        self.jitter_threshold_ps = 740  # SMPTE ê·œê²©: < 0.2 UI (740ps @ 3G-SDI)
        self.amplitude_min = 800  # mV (Â±10%)
        self.amplitude_max = 880  # mV

    def analyze_eye_pattern(self) -> dict:
        """Eye Pattern ë¶„ì„"""

        # ì‹ í˜¸ ìƒ˜í”Œë§
        samples = self.device.capture_samples(duration_ms=100)

        # Eye Opening ì¸¡ì •
        eye_height = self._measure_eye_height(samples)
        eye_width = self._measure_eye_width(samples)

        # Jitter ì¸¡ì •
        jitter_rms = self._measure_jitter_rms(samples)
        jitter_peak = self._measure_jitter_peak(samples)

        # Rise/Fall Time
        rise_time = self._measure_rise_time(samples)
        fall_time = self._measure_fall_time(samples)

        # í’ˆì§ˆ í‰ê°€
        quality = self._evaluate_quality(eye_height, eye_width, jitter_rms)

        return {
            "eye_height_mv": eye_height,
            "eye_width_ps": eye_width,
            "jitter_rms_ps": jitter_rms,
            "jitter_peak_ps": jitter_peak,
            "rise_time_ps": rise_time,
            "fall_time_ps": fall_time,
            "quality_score": quality,
            "pass_smpte": jitter_rms < self.jitter_threshold_ps
        }

    def _evaluate_quality(self, eye_height, eye_width, jitter) -> str:
        """ì‹ í˜¸ í’ˆì§ˆ í‰ê°€"""

        if eye_height > 700 and eye_width > 500 and jitter < 500:
            return "Excellent"
        elif eye_height > 600 and eye_width > 400 and jitter < 700:
            return "Good"
        elif eye_height > 500 and eye_width > 300 and jitter < 740:
            return "Acceptable"
        else:
            return "Poor - Check cable/connections"

    def generate_report(self, analysis: dict) -> str:
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""

        report = "=== SDI Signal Analysis Report ===\n\n"
        report += f"Eye Height: {analysis['eye_height_mv']:.1f} mV\n"
        report += f"Eye Width: {analysis['eye_width_ps']:.0f} ps\n"
        report += f"Jitter (RMS): {analysis['jitter_rms_ps']:.1f} ps\n"
        report += f"Jitter (Peak-Peak): {analysis['jitter_peak_ps']:.1f} ps\n"
        report += f"Rise Time: {analysis['rise_time_ps']:.0f} ps\n"
        report += f"Fall Time: {analysis['fall_time_ps']:.0f} ps\n\n"
        report += f"Quality: {analysis['quality_score']}\n"
        report += f"SMPTE Compliant: {'YES' if analysis['pass_smpte'] else 'NO'}\n"

        return report
```

#### SDI í´ë¡ ë³µì› (Clock Recovery)
```yaml
SDI ìˆ˜ì‹  í”„ë¡œì„¸ìŠ¤:
  1. Cable Equalization:
     - ì¼€ì´ë¸” ì†ì‹¤ ë³´ìƒ
     - ê³ ì£¼íŒŒ ì„±ë¶„ ë³µì›
     - Adaptive EQ ì‚¬ìš©

  2. Clock Recovery:
     - PLL (Phase-Locked Loop)ì„ ì´ìš©í•œ í´ë¡ ì¶”ì¶œ
     - ì„ë² ë””ë“œ í´ë¡ ì‹ í˜¸ ë³µì›
     - Jitter ì œê±°

  3. Data Deserializing:
     - ì§ë ¬ â†’ ë³‘ë ¬ ë³€í™˜
     - 10-bit ì›Œë“œ ë³µì›
     - Timing Reference Signals (TRS) ê°ì§€

  4. Error Detection:
     - CRC ì²´í¬ì„¬ ê²€ì¦
     - Line Number/CRC (LN/CRC)
     - ì—ëŸ¬ ë°œìƒ ì‹œ ì•Œë¦¼
```

### ğŸ¯ SDI ë¼ìš°íŒ… ë§¤íŠ¸ë¦­ìŠ¤

```python
class SDIRouter:
    """SDI ë¼ìš°íŒ… ë§¤íŠ¸ë¦­ìŠ¤ ì œì–´"""

    def __init__(self, router_ip: str):
        self.router_ip = router_ip
        self.input_count = 64
        self.output_count = 64
        self.routing_table = {}

    def route(self, input_num: int, output_num: int, level: str = "video+audio"):
        """ì…ë ¥ì„ ì¶œë ¥ìœ¼ë¡œ ë¼ìš°íŒ…"""

        if not (1 <= input_num <= self.input_count):
            raise ValueError(f"Invalid input: {input_num}")

        if not (1 <= output_num <= self.output_count):
            raise ValueError(f"Invalid output: {output_num}")

        # Videohub í”„ë¡œí† ì½œ ëª…ë ¹
        command = f"VIDEO OUTPUT ROUTING:\n{output_num-1} {input_num-1}\n\n"

        self._send_command(command)
        self.routing_table[output_num] = input_num

        print(f"Routed Input {input_num} â†’ Output {output_num}")

    def get_routing_status(self) -> dict:
        """í˜„ì¬ ë¼ìš°íŒ… ìƒíƒœ ì¡°íšŒ"""

        status = {}
        for output, input_source in self.routing_table.items():
            status[f"Output_{output}"] = f"Input_{input_source}"

        return status

    def save_preset(self, preset_name: str):
        """í˜„ì¬ ë¼ìš°íŒ…ì„ í”„ë¦¬ì…‹ìœ¼ë¡œ ì €ì¥"""

        preset = {
            "name": preset_name,
            "timestamp": time.time(),
            "routing": self.routing_table.copy()
        }

        # í”„ë¦¬ì…‹ íŒŒì¼ ì €ì¥
        with open(f"routing_presets/{preset_name}.json", "w") as f:
            json.dump(preset, f, indent=2)

        print(f"Routing preset '{preset_name}' saved")

    def recall_preset(self, preset_name: str):
        """í”„ë¦¬ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°"""

        with open(f"routing_presets/{preset_name}.json", "r") as f:
            preset = json.load(f)

        # ëª¨ë“  ë¼ìš°íŒ… ì ìš©
        for output, input_source in preset["routing"].items():
            self.route(input_source, output)

        print(f"Routing preset '{preset_name}' recalled")

# í¬ì»¤ ë°©ì†¡ ë¼ìš°íŒ… ì˜ˆì‹œ
router = SDIRouter("192.168.10.10")

# ë©”ì¸ í”„ë¡œê·¸ë¨ ë¼ìš°íŒ…
router.route(input_num=1, output_num=1)   # Camera 1 â†’ Switcher Input 1
router.route(input_num=2, output_num=2)   # Camera 2 â†’ Switcher Input 2
router.route(input_num=11, output_num=20) # Switcher PGM â†’ Encoder
router.route(input_num=11, output_num=21) # Switcher PGM â†’ Backup Recorder

# í”„ë¦¬ì…‹ ì €ì¥
router.save_preset("poker_tournament_main")
```

### ğŸ“Š SDI ëª¨ë‹ˆí„°ë§

```python
import matplotlib.pyplot as plt
import numpy as np

class SDIMonitor:
    """SDI ì‹ í˜¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.history_length = 300  # 10ì´ˆ @ 30fps
        self.signal_history = []

    def monitor_signal_quality(self, sdi_analyzer: SDIAnalyzer):
        """ì‹ í˜¸ í’ˆì§ˆ ì—°ì† ëª¨ë‹ˆí„°ë§"""

        while True:
            analysis = sdi_analyzer.analyze_eye_pattern()

            self.signal_history.append(analysis)
            if len(self.signal_history) > self.history_length:
                self.signal_history.pop(0)

            # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ê²½ê³ 
            if analysis["jitter_rms_ps"] > 700:
                self._send_alert(f"High jitter detected: {analysis['jitter_rms_ps']:.1f} ps")

            if analysis["eye_height_mv"] < 600:
                self._send_alert(f"Low signal amplitude: {analysis['eye_height_mv']:.1f} mV")

            time.sleep(0.1)  # 100ms

    def plot_jitter_trend(self):
        """Jitter íŠ¸ë Œë“œ ê·¸ë˜í”„"""

        if len(self.signal_history) < 10:
            return

        times = range(len(self.signal_history))
        jitter_values = [h["jitter_rms_ps"] for h in self.signal_history]

        plt.figure(figsize=(12, 4))
        plt.plot(times, jitter_values, label="Jitter (RMS)")
        plt.axhline(y=740, color='r', linestyle='--', label="SMPTE Limit (740ps)")
        plt.xlabel("Sample")
        plt.ylabel("Jitter (ps)")
        plt.title("SDI Jitter Monitoring (Last 10 seconds)")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        return plt
```

---

<a name="7-hdmi-vs-sdi"></a>
## 7ï¸âƒ£ HDMI vs SDI ë¹„êµ

### ğŸ“˜ ì •ì˜
**HDMI**ëŠ” ê°€ì „ìš© ë””ì§€í„¸ ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ì¸í„°í˜ì´ìŠ¤ì´ë©°, **SDI**ëŠ” ë°©ì†¡ìš© í”„ë¡œí˜ì…”ë„ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. í¬ì»¤ í”„ë¡œë•ì…˜ì—ì„œëŠ” ìš©ë„ì— ë”°ë¼ êµ¬ë¶„í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ğŸ”§ ìƒì„¸ ë¹„êµ

#### ê¸°ìˆ ì  ì°¨ì´ì 
```yaml
HDMI (High-Definition Multimedia Interface):
  ê°œë°œ: Consumer Electronics ìš©
  ì‹ í˜¸: TMDS (Transition-Minimized Differential Signaling)
  ì»¤ë„¥í„°: Type-A (í‘œì¤€), Type-C (ë¯¸ë‹ˆ), Type-D (ë§ˆì´í¬ë¡œ)
  ì¼€ì´ë¸”: 4ìŒ ì°¨ë™ ì‹ í˜¸ì„ 
  ìµœëŒ€ ê±°ë¦¬:
    - HDMI 1.4: 15m (1080p)
    - HDMI 2.0: 10m (4K30)
    - HDMI 2.1: 5m (4K120, 8K60)
  í™•ì¥: HDMI over Fiber (ìµœëŒ€ 100m+)

  ì¥ì :
    - ì €ë ´í•œ ê°€ê²©
    - ë„ë¦¬ ë³´ê¸‰ë¨
    - HDCP ì§€ì› (ì½˜í…ì¸  ë³´í˜¸)
    - CEC (ê¸°ê¸° ê°„ ì œì–´)
    - ARC/eARC (ì˜¤ë””ì˜¤ ë¦¬í„´)

  ë‹¨ì :
    - ì§§ì€ ì¼€ì´ë¸” ê¸¸ì´
    - í•«í”ŒëŸ¬ê·¸ ì‹œ ì‹ í˜¸ ëŠê¹€
    - ë ˆì´í„´ì‹œ (ìˆ˜ì‹­ ms)
    - ì„ë² ë””ë“œ íƒ€ì„ì½”ë“œ ì—†ìŒ

SDI (Serial Digital Interface):
  ê°œë°œ: ë°©ì†¡ í”„ë¡œë•ì…˜ ìš©
  ì‹ í˜¸: NRZ (Non-Return-to-Zero) ì§ë ¬
  ì»¤ë„¥í„°: BNC (75Î©)
  ì¼€ì´ë¸”: RG-6 ë™ì¶• ì¼€ì´ë¸”
  ìµœëŒ€ ê±°ë¦¬:
    - HD-SDI: 100m
    - 3G-SDI: 100m
    - 12G-SDI: 70m
  í™•ì¥: SDI over Fiber (ìµœëŒ€ 10km+)

  ì¥ì :
    - ê¸´ ì¼€ì´ë¸” ê¸¸ì´
    - í•«í”ŒëŸ¬ê·¸ ì•ˆì „
    - ë‚®ì€ ë ˆì´í„´ì‹œ (<1ms)
    - ì„ë² ë””ë“œ ì˜¤ë””ì˜¤ (ìµœëŒ€ 16ì±„ë„)
    - íƒ€ì„ì½”ë“œ ì„ë² ë””ë“œ
    - ì•ˆì •ì ì¸ í´ë¡ ë™ê¸°

  ë‹¨ì :
    - ë¹„ì‹¼ ê°€ê²©
    - ì „ë¬¸ ì¥ë¹„ í•„ìš”
    - ì†Œë¹„ì ê¸°ê¸° ë¯¸ì§€ì›
```

#### í¬ì»¤ í”„ë¡œë•ì…˜ ì‚¬ìš© ê°€ì´ë“œ
```yaml
SDI ì‚¬ìš© ê¶Œì¥:
  - ì¹´ë©”ë¼ â†’ ìŠ¤ìœ„ì²˜
  - ìŠ¤ìœ„ì²˜ â†’ ë ˆì½”ë”
  - ìŠ¤ìœ„ì²˜ â†’ ëª¨ë‹ˆí„° (TD, ê°ë…)
  - ì¥ê±°ë¦¬ ì „ì†¡ (50m+)
  - íƒ€ì„ì½”ë“œ ë™ê¸° í•„ìˆ˜

HDMI ì‚¬ìš© ê°€ëŠ¥:
  - ì»´í“¨í„° ê·¸ë˜í”½ â†’ ìº¡ì²˜ ì¹´ë“œ
  - ë¡œì»¬ ëª¨ë‹ˆí„° (í”„ë¡œë“€ì„œ ë°ìŠ¤í¬)
  - í”„ë¦¬ë·° ëª¨ë‹ˆí„° (ë‹¨ê±°ë¦¬)
  - ë°±ì—… ë ˆì½”ë” (HDMI ì…ë ¥ë§Œ ìˆëŠ” ê²½ìš°)

HDMI â†’ SDI ë³€í™˜:
  - Blackmagic Micro Converter
  - AJA Hi5-4K-Plus
  - Decimator MD-HX

2. í”Œë ˆì´ì–´ â†’ ì»¤ë®¤ë‹ˆí‹° ì¹´ë“œ
   - í”Œë ˆì´ì–´ í‘œì • â†’ ì¹´ë“œ ê³µê°œ
   - Duration: 1.0 ~ 1.5ì´ˆ

3. ì¹© ìŠ¤íƒ â†’ í”Œë ˆì´ì–´ ì–¼êµ´
   - ì˜¬ì¸ ì¹© â†’ í”Œë ˆì´ì–´ ê¸´ì¥ê°
   - Duration: 1.5 ~ 2.0ì´ˆ

ì£¼ì˜ì‚¬í•­:
- ë„ˆë¬´ ë¹ ë¥´ë©´ ì‹œì²­ì í˜¼ë€
- ë„ˆë¬´ ëŠë¦¬ë©´ ì§€ë£¨í•¨
- ìµœì : 1.0 ~ 1.5ì´ˆ (ë¶€ë“œëŸ¬ìš´ ì „í™˜)
```

#### Follow Focus (íŒ”ë¡œìš° í¬ì»¤ìŠ¤)
```markdown
ì •ì˜: ì›€ì§ì´ëŠ” í”¼ì‚¬ì²´ë¥¼ ë”°ë¼ê°€ë©° ì´ˆì ì„ ìœ ì§€í•˜ëŠ” ê¸°ë²•

í¬ì»¤ ë°©ì†¡ í™œìš©:
1. ì¹´ë“œ ë°°ë¶„ ì¥ë©´
   - ë”œëŸ¬ ì† â†’ í”Œë ˆì´ì–´ ì•
   - ì—°ì† ì´ˆì  ì¶”ì 

2. ì¹© í‘¸ì‹œ
   - í”Œë ˆì´ì–´ ì¹© â†’ ì¤‘ì•™ íŒŸ
   - ì›€ì§ì„ì— ë§ì¶˜ ì´ˆì 

3. í”Œë ˆì´ì–´ ì´ë™
   - ìë¦¬ ì´ë™, ìŠ¤íŠ¸ë ˆì¹­
   - AF-C ëª¨ë“œ í™œìš©

êµ¬í˜„ (AF-C + ìˆ˜ë™ ë³´ì •):
```python
def follow_focus_with_assist(camera, af_mode="continuous"):
    """AF-C + ìˆ˜ë™ ë³´ì • í•˜ì´ë¸Œë¦¬ë“œ"""

    # AF-C í™œì„±í™”
    camera.set_af_mode("AF-C")
    camera.set_af_area("zone")  # ì¤‘ì•™ zone

    # ìˆ˜ë™ ë³´ì • ë£¨í”„
    while True:
        # AF-Cê°€ ì¶”ì  ì¤‘
        af_status = camera.get_af_status()

        if af_status["tracking_confidence"] < 0.7:
            # ì¶”ì  ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ê°œì…
            manual_adjust = calculate_manual_correction(
                af_status["current_focus"],
                af_status["subject_distance"]
            )
            camera.adjust_focus_offset(manual_adjust)

        time.sleep(0.033)  # 30fps
```
```

### ğŸ“Š ì´ˆì  ì •í™•ë„ ëª¨ë‹ˆí„°ë§

```python
import cv2
import numpy as np

class FocusAccuracyMonitor:
    """ì´ˆì  ì •í™•ë„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.focus_history = []
        self.sharpness_threshold = 0.6  # 0.0 ~ 1.0

    def measure_sharpness(self, frame: np.ndarray, roi=None) -> float:
        """í”„ë ˆì„ì˜ ì„ ëª…ë„ ì¸¡ì • (Laplacian ë°©ë²•)"""

        # ROI ì§€ì • (ê´€ì‹¬ ì˜ì—­ë§Œ ì¸¡ì •)
        if roi:
            x, y, w, h = roi
            frame = frame[y:y+h, x:x+w]

        # Grayscale ë³€í™˜
        if len(frame.shape) == 3:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray = frame

        # Laplacian edge detection
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        sharpness = laplacian.var()

        # ì •ê·œí™” (0.0 ~ 1.0)
        sharpness_normalized = min(sharpness / 1000.0, 1.0)

        return sharpness_normalized

    def detect_focus_breathing(self, frames: list) -> dict:
        """í¬ì»¤ìŠ¤ ë¸Œë¦¬ë”© (ì´ˆì  ë³€í™” ì‹œ í™”ê° ë³€í™”) ê²€ì¶œ"""

        if len(frames) < 2:
            return {"breathing_detected": False}

        # ì²« í”„ë ˆì„ê³¼ ë§ˆì§€ë§‰ í”„ë ˆì„ ë¹„êµ
        frame1 = frames[0]
        frame2 = frames[-1]

        # Feature ë§¤ì¹­ìœ¼ë¡œ ìŠ¤ì¼€ì¼ ë³€í™” ì¸¡ì •
        orb = cv2.ORB_create()
        kp1, des1 = orb.detectAndCompute(frame1, None)
        kp2, des2 = orb.detectAndCompute(frame2, None)

        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)

        # ë§¤ì¹­ ê±°ë¦¬ í‰ê· 
        avg_distance = np.mean([m.distance for m in matches])

        breathing_detected = avg_distance > 50  # ì„ê³„ê°’

        return {
            "breathing_detected": breathing_detected,
            "avg_match_distance": avg_distance,
            "recommendation": "Use lens with minimal focus breathing" if breathing_detected else "OK"
        }

    def generate_focus_peaking(self, frame: np.ndarray, color=(0, 255, 0)) -> np.ndarray:
        """Focus Peaking ì˜¤ë²„ë ˆì´ ìƒì„± (ì´ˆì  ë§ì€ ì˜ì—­ í•˜ì´ë¼ì´íŠ¸)"""

        # Grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Edge detection
        edges = cv2.Canny(gray, 100, 200)

        # ê²°ê³¼ í”„ë ˆì„ì— ìƒ‰ìƒ ì˜¤ë²„ë ˆì´
        result = frame.copy()
        result[edges > 0] = color

        return result
```

---

<a name="5-ptz-camera"></a>
## 5ï¸âƒ£ PTZ (Pan-Tilt-Zoom) ì¹´ë©”ë¼

### ğŸ“˜ ì •ì˜
**PTZ ì¹´ë©”ë¼**ëŠ” ì›ê²©ìœ¼ë¡œ Pan (ì¢Œìš° íšŒì „), Tilt (ìƒí•˜ íšŒì „), Zoom (í™•ëŒ€/ì¶•ì†Œ)ì„ ì œì–´í•  ìˆ˜ ìˆëŠ” ì¹´ë©”ë¼ë¡œ, í¬ì»¤ ë°©ì†¡ì—ì„œ FR7ì˜ ë°±ì—…ì´ë‚˜ ë³´ì¡° ì¹´ë©”ë¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

### ğŸ”§ ê¸°ìˆ  ì‚¬ì–‘

#### PTZ vs FR7 ë¹„êµ
```yaml
PTZ ì¹´ë©”ë¼ (ì˜ˆ: Sony BRC-X1000):
  Pan: 360ë„ (ì†ë„: 0.3Â°/s ~ 300Â°/s)
  Tilt: Â±30ë„ (ì†ë„: 0.25Â°/s ~ 300Â°/s)
  Zoom: 30x ê´‘í•™ ì¤Œ
  í”„ë¦¬ì…‹: 256ê°œ
  ì œì–´: VISCA over IP, RS-422
  ê°€ê²©: $5,000 ~ $8,000

  ì¥ì :
    - ì €ë ´í•œ ê°€ê²©
    - ë¹ ë¥¸ ì„¤ì¹˜
    - ë‹¤ì–‘í•œ í”„ë¦¬ì…‹

  ë‹¨ì :
    - í™”ì§ˆ ì œí•œ (1080p)
    - í‹¸íŠ¸ ë²”ìœ„ ì¢ìŒ
    - ì„¼ì„œ í¬ê¸° ì‘ìŒ (1/2.8")

FR7 ë¡œë´‡ ì¹´ë©”ë¼:
  Pan: 360ë„ ë¬´í•œ íšŒì „
  Tilt: Â±210ë„
  Zoom: ë Œì¦ˆ êµì²´ ê°€ëŠ¥
  í”„ë¦¬ì…‹: 99ê°œ
  ì œì–´: IP (REST API), RS-422
  ê°€ê²©: $25,000 ~ $35,000

  ì¥ì :
    - ê³ í™”ì§ˆ (4K)
    - ë„“ì€ í‹¸íŠ¸ ë²”ìœ„
    - í’€í”„ë ˆì„ ì„¼ì„œ
    - ë Œì¦ˆ êµí™˜

  ë‹¨ì :
    - ë†’ì€ ê°€ê²©
    - ë³µì¡í•œ ì„¤ì •
    - ìœ ì§€ë³´ìˆ˜ ë¹„ìš©

í¬ì»¤ ë°©ì†¡ ê¶Œì¥ êµ¬ì„±:
  ë©”ì¸ ì¹´ë©”ë¼: FR7 x 3ëŒ€
  ë³´ì¡° ì¹´ë©”ë¼: PTZ x 2ëŒ€
  ë°±ì—… ì¹´ë©”ë¼: PTZ x 1ëŒ€
```

#### PTZ ì œì–´ í”„ë¡œí† ì½œ (VISCA)
```python
import socket

class VISCAController:
    """VISCA over IP í”„ë¡œí† ì½œ PTZ ì œì–´"""

    def __init__(self, camera_ip: str, port: int = 52381):
        self.camera_ip = camera_ip
        self.port = port
        self.socket = None
        self.camera_id = 1  # VISCA Address (1~7)

    def connect(self):
        """ì¹´ë©”ë¼ ì—°ê²°"""
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.connect((self.camera_ip, self.port))
        print(f"Connected to PTZ camera at {self.camera_ip}:{self.port}")

    def disconnect(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.socket:
            self.socket.close()

    def _send_command(self, command: bytes) -> bytes:
        """VISCA ëª…ë ¹ ì „ì†¡"""
        # VISCA íŒ¨í‚· êµ¬ì¡°: Header + Command + Terminator
        packet = bytes([0x80 + self.camera_id]) + command + bytes([0xFF])

        self.socket.sendall(packet)
        response = self.socket.recv(1024)

        return response

    def pan_tilt(self, pan_speed: int, tilt_speed: int,
                 pan_pos: int, tilt_pos: int):
        """Pan/Tilt ì ˆëŒ€ ìœ„ì¹˜ ì´ë™"""

        # VISCA ëª…ë ¹: 8x 01 06 02 VV WW 0Y 0Y 0Y 0Y 0Z 0Z 0Z 0Z FF
        # VV: Pan speed (1~24)
        # WW: Tilt speed (1~20)
        # YYYY: Pan position (-1440 ~ +1440)
        # ZZZZ: Tilt position (-360 ~ +360)

        command = bytes([
            0x01, 0x06, 0x02,
            pan_speed & 0xFF,
            tilt_speed & 0xFF,
            (pan_pos >> 12) & 0x0F,
            (pan_pos >> 8) & 0x0F,
            (pan_pos >> 4) & 0x0F,
            pan_pos & 0x0F,
            (tilt_pos >> 12) & 0x0F,
            (tilt_pos >> 8) & 0x0F,
            (tilt_pos >> 4) & 0x0F,
            tilt_pos & 0x0F
        ])

        return self._send_command(command)

    def zoom(self, zoom_pos: int):
        """Zoom ì ˆëŒ€ ìœ„ì¹˜"""

        # VISCA ëª…ë ¹: 8x 01 04 47 0p 0p 0p 0p FF
        # pppp: Zoom position (0x0000 ~ 0x4000)

        command = bytes([
            0x01, 0x04, 0x47,
            (zoom_pos >> 12) & 0x0F,
            (zoom_pos >> 8) & 0x0F,
            (zoom_pos >> 4) & 0x0F,
            zoom_pos & 0x0F
        ])

        return self._send_command(command)

    def recall_preset(self, preset_number: int):
        """í”„ë¦¬ì…‹ í˜¸ì¶œ"""

        # VISCA ëª…ë ¹: 8x 01 04 3F 02 pp FF
        # pp: Preset number (0~255)

        command = bytes([0x01, 0x04, 0x3F, 0x02, preset_number & 0xFF])

        return self._send_command(command)

    def save_preset(self, preset_number: int):
        """í˜„ì¬ ìœ„ì¹˜ë¥¼ í”„ë¦¬ì…‹ìœ¼ë¡œ ì €ì¥"""

        # VISCA ëª…ë ¹: 8x 01 04 3F 01 pp FF

        command = bytes([0x01, 0x04, 0x3F, 0x01, preset_number & 0xFF])

        return self._send_command(command)

    def get_position(self) -> dict:
        """í˜„ì¬ Pan/Tilt/Zoom ìœ„ì¹˜ ì¡°íšŒ"""

        # VISCA ëª…ë ¹: 8x 09 06 12 FF
        command = bytes([0x09, 0x06, 0x12])
        response = self._send_command(command)

        # ì‘ë‹µ íŒŒì‹±: y0 50 0p 0p 0p 0p 0t 0t 0t 0t 0z 0z 0z 0z FF
        if len(response) >= 15:
            pan = ((response[2] & 0x0F) << 12) | ((response[3] & 0x0F) << 8) | \
                  ((response[4] & 0x0F) << 4) | (response[5] & 0x0F)

            tilt = ((response[6] & 0x0F) << 12) | ((response[7] & 0x0F) << 8) | \
                   ((response[8] & 0x0F) << 4) | (response[9] & 0x0F)

            zoom = ((response[10] & 0x0F) << 12) | ((response[11] & 0x0F) << 8) | \
                   ((response[12] & 0x0F) << 4) | (response[13] & 0x0F)

            return {
                "pan": pan - 1440,  # ì¤‘ì•™ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
                "tilt": tilt - 360,
                "zoom": zoom
            }

        return {"error": "Invalid response"}

# ì‚¬ìš© ì˜ˆì‹œ
ptz = VISCAController("192.168.10.201")
ptz.connect()

# í…Œì´ë¸” ì „ì²´ ìƒ· (í”„ë¦¬ì…‹ 1)
ptz.recall_preset(1)

# í”Œë ˆì´ì–´ 3ë²ˆ í´ë¡œì¦ˆì—…
ptz.pan_tilt(pan_speed=15, tilt_speed=15, pan_pos=450, tilt_pos=-50)
ptz.zoom(0x2000)  # 50% zoom

ptz.disconnect()
```

### ğŸ’¡ PTZ ë°±ì—… ì‹œìŠ¤í…œ

```python
class PTZBackupSystem:
    """FR7 ì¥ì•  ì‹œ PTZ ìë™ ì „í™˜"""

    def __init__(self):
        self.fr7_cameras = []
        self.ptz_cameras = []
        self.backup_mapping = {}

    def configure_backup(self, fr7_id: str, ptz_id: str):
        """FR7 - PTZ ë°±ì—… ë§¤í•‘"""
        self.backup_mapping[fr7_id] = ptz_id
        print(f"Backup configured: {fr7_id} â†’ {ptz_id}")

    def monitor_fr7_health(self):
        """FR7 ìƒíƒœ ëª¨ë‹ˆí„°ë§"""

        while True:
            for fr7 in self.fr7_cameras:
                health = self._check_camera_health(fr7)

                if not health["online"]:
                    # FR7 ì¥ì•  ê°ì§€
                    print(f"FR7 {fr7.id} is offline! Activating backup...")
                    self._activate_ptz_backup(fr7.id)

            time.sleep(5)  # 5ì´ˆë§ˆë‹¤ ì²´í¬

    def _activate_ptz_backup(self, failed_fr7_id: str):
        """PTZ ë°±ì—… ì¹´ë©”ë¼ í™œì„±í™”"""

        ptz_id = self.backup_mapping.get(failed_fr7_id)
        if not ptz_id:
            print(f"No backup configured for {failed_fr7_id}")
            return

        # 1. PTZ ì¹´ë©”ë¼ ì°¾ê¸°
        ptz = self._get_ptz_camera(ptz_id)

        # 2. FR7ì˜ ë§ˆì§€ë§‰ í”„ë¦¬ì…‹ ê°€ì ¸ì˜¤ê¸°
        last_preset = self._get_last_fr7_preset(failed_fr7_id)

        # 3. PTZë¥¼ ìœ ì‚¬í•œ ìœ„ì¹˜ë¡œ ì´ë™
        ptz_preset = self._convert_fr7_to_ptz_preset(last_preset)
        ptz.recall_preset(ptz_preset)

        # 4. ë¹„ì „ ë¯¹ì„œì—ì„œ ì†ŒìŠ¤ ì „í™˜
        self._switch_video_source(failed_fr7_id, ptz_id)

        # 5. ì•Œë¦¼
        self._send_alert(f"Switched from FR7 {failed_fr7_id} to PTZ {ptz_id}")

    def _convert_fr7_to_ptz_preset(self, fr7_preset: dict) -> int:
        """FR7 í”„ë¦¬ì…‹ì„ PTZ í”„ë¦¬ì…‹ìœ¼ë¡œ ë³€í™˜"""

        # FR7 í”„ë¦¬ì…‹ ë§¤í•‘ í…Œì´ë¸”
        mapping = {
            "table_wide": 1,
            "player_1": 11,
            "player_2": 12,
            # ... ë“±ë“±
            "community_cards": 20
        }

        return mapping.get(fr7_preset["name"], 1)  # ê¸°ë³¸ê°’ 1
```

---

ì´ì œ ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ì„ ì´ì–´ì„œ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤. ë¬¸ì„œê°€ ë§¤ìš° ê¸¸ì–´ì§ˆ ì˜ˆì •ì´ë¯€ë¡œ, ê³„ì† ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.
